{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd37cf4",
   "metadata": {
    "id": "a461c72d"
   },
   "source": [
    "# OptiGuide Example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc333c12",
   "metadata": {
    "id": "59a05fc7"
   },
   "source": [
    "Here we give a simple example, as designed and illustrated in the [OptiGuide paper](https://arxiv.org/abs/2307.03875).\n",
    "While the original paper is designed specifically for supply chain optimization, the general framework can be easily adapted to other applications with coding capacity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df57b42",
   "metadata": {
    "id": "5e92d200"
   },
   "source": [
    "## OptiGuide for Supply Chain Optimization: System Design Overview\n",
    "\n",
    "The original system design for OptiGuide, tailored for supply chain optimization, is presented below.\n",
    "\n",
    "The collaboration among three agents -- Coder, Safeguard, and Interpreter -- lies at the core of this system. They leverage a set of external tools and a large language model (LLM) to address users' questions related to supply chain applications. For a comprehensive understanding of the design and data flow, detailed information can be found in the original [paper](https://arxiv.org/abs/2307.03875).\n",
    "\n",
    "\n",
    "![optiguide system](https://www.beibinli.com/docs/optiguide/optiguide_system.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec618de",
   "metadata": {
    "id": "8b7f90c8"
   },
   "source": [
    "## New Implementation\n",
    "\n",
    "\n",
    "\n",
    "![](new_design.png)\n",
    "\n",
    "Advantages of this multi-agent design with autogen:\n",
    "- Collaborative Problem Solving: The collaboration among the user proxy agent and the assistant agents fosters a cooperative problem-solving environment. The agents can share information and knowledge, allowing them to complement each other's abilities and collectively arrive at better solutions. On the other hand, the Safeguard acts as a virtual adversarial checker, which can perform another safety check pass on the generated code.\n",
    "\n",
    "- Modularity: The division of tasks into separate agents promotes modularity in the system. Each agent can be developed, tested, and maintained independently, simplifying the overall development process and facilitating code management.\n",
    "\n",
    "- Memory Management: The OptiGuide agent's role in maintaining memory related to user interactions is crucial. The memory retention allows the agents to have context about a user's prior questions, making the decision-making process more informed and context-aware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444fe547",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReAgLnDma3oI",
    "outputId": "c95a23e8-ddb9-4fd2-f218-c40a51cbcbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/frozendict-2.3.0-py3.10.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai==0.28.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from openai==0.28.1) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from openai==0.28.1) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from openai==0.28.1) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28.1) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28.1) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28.1) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28.1) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28.1) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28.1) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/frozendict-2.3.0-py3.10.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: FLAML==2.1.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from FLAML==2.1.1) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/frozendict-2.3.0-py3.10.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gurobi-machinelearning==1.3.3 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from gurobi-machinelearning==1.3.3) (1.23.5)\n",
      "Requirement already satisfied: gurobipy>=10.0.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from gurobi-machinelearning==1.3.3) (10.0.0)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from gurobi-machinelearning==1.3.3) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/frozendict-2.3.0-py3.10.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gurobipy==10.0.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (10.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/frozendict-2.3.0-py3.10.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gurobipy-pandas==1.0.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: gurobipy>=9.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from gurobipy-pandas==1.0.0) (10.0.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from gurobipy-pandas==1.0.0) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->gurobipy-pandas==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->gurobipy-pandas==1.0.0) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->gurobipy-pandas==1.0.0) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas>=1.0->gurobipy-pandas==1.0.0) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/frozendict-2.3.0-py3.10.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: autogen==1.0.16 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (1.0.16)\n",
      "Requirement already satisfied: PyYAML in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from autogen==1.0.16) (6.0)\n",
      "Requirement already satisfied: autopep8 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from autogen==1.0.16) (1.6.0)\n",
      "Requirement already satisfied: docopt in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from autogen==1.0.16) (0.6.2)\n",
      "Requirement already satisfied: setuptools in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from autogen==1.0.16) (68.0.0)\n",
      "Requirement already satisfied: twine in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from autogen==1.0.16) (4.0.2)\n",
      "Requirement already satisfied: pycodestyle>=2.8.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from autopep8->autogen==1.0.16) (2.10.0)\n",
      "Requirement already satisfied: toml in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from autopep8->autogen==1.0.16) (0.10.2)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (1.9.6)\n",
      "Requirement already satisfied: readme-renderer>=35.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (42.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (2.28.1)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (1.26.16)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (6.0.0)\n",
      "Requirement already satisfied: keyring>=15.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (23.13.1)\n",
      "Requirement already satisfied: rfc3986>=1.4.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (2.0.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from twine->autogen==1.0.16) (13.7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from importlib-metadata>=3.6->twine->autogen==1.0.16) (3.11.0)\n",
      "Requirement already satisfied: jaraco.classes in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from keyring>=15.1->twine->autogen==1.0.16) (3.2.1)\n",
      "Requirement already satisfied: nh3>=0.2.14 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->autogen==1.0.16) (0.2.14)\n",
      "Requirement already satisfied: docutils>=0.13.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->autogen==1.0.16) (0.18.1)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->autogen==1.0.16) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->twine->autogen==1.0.16) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->twine->autogen==1.0.16) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->twine->autogen==1.0.16) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from rich>=12.0.0->twine->autogen==1.0.16) (2.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->autogen==1.0.16) (0.1.0)\n",
      "Requirement already satisfied: more-itertools in /Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages (from jaraco.classes->keyring>=15.1->twine->autogen==1.0.16) (8.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==0.28.1\n",
    "%pip install FLAML==2.1.1\n",
    "%pip install gurobi-machinelearning==1.3.3\n",
    "%pip install gurobipy==10.0.0\n",
    "%pip install gurobipy-pandas==1.0.0\n",
    "%pip install autogen==1.0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43cc7263",
   "metadata": {
    "id": "9a3b79c4"
   },
   "outputs": [],
   "source": [
    "# test Gurobi installation\n",
    "# %pip install autogen\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from eventlet.timeout import Timeout\n",
    "\n",
    "# import auxillary packages\n",
    "import requests  # for loading the example source code\n",
    "import openai\n",
    "\n",
    "\n",
    "from flaml.autogen.agentchat import Agent, UserProxyAgent\n",
    "from flaml.autogen.agentchat import AssistantAgent\n",
    "from flaml.autogen.agentchat.agent import Agent\n",
    "from flaml.autogen.code_utils import extract_code\n",
    "from flaml import autogen \n",
    "\n",
    "from optiguide.optiguide import OptiGuideAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08c1e211",
   "metadata": {
    "id": "aedf19e7"
   },
   "outputs": [],
   "source": [
    "#autogen.oai.ChatCompletion.start_logging()\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            #\"gpt-4\",\n",
    "            #\"gpt4\",\n",
    "            #\"gpt-4-32k\",\n",
    "            #\"gpt-4-32k-0314\",\n",
    "            #\"gpt-3.5-turbo\"\n",
    "            \"gpt-3.5-turbo-16k\"\n",
    "            #\"gpt-3.5-turbo-0301\",\n",
    "            #\"chatgpt-35-turbo-0301\",\n",
    "            #\"gpt-35-turbo-v0301\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "config_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944272d",
   "metadata": {
    "id": "e9e7e728"
   },
   "source": [
    "Now, let's import the source code (loading from URL) and also some training examples (defined as string blow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05664eac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca962ac5",
    "outputId": "4a789991-8ba1-46f3-aad5-7fbaaaff7f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import re\n",
      "import sys\n",
      "import time\n",
      "import shutil\n",
      "import zipfile\n",
      "import requests\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import gurobipy as gp\n",
      "from selenium import webdriver\n",
      "from datetime import datetime, timedelta\n",
      "from webdriver_manager.chrome import ChromeDriverManager\n",
      "\n",
      "columns = ['Time Stamp', 'LBMP ($/MWHr)', 'Marginal Cost Losses ($/MWHr)', 'Marginal Cost Congestion ($/MWHr)']\n",
      "new_columns = {\n",
      "    'Time Stamp': 'time',\n",
      "    'LBMP ($/MWHr)': 'LB_MargPrice',\n",
      "    'Marginal Cost Losses ($/MWHr)': 'MargCostLosses',\n",
      "    'Marginal Cost Congestion ($/MWHr)': 'MargCostCongestion'\n",
      "}\n",
      "\n",
      "home_dir = os.path.expanduser(\"~\")\n",
      "download_directory = os.path.join(home_dir, 'Downloads_CSV')\n",
      "storage_directory = 'Data'\n",
      "\n",
      "def extract_date(file_path):\n",
      "    match = re.match(r'^(\\d+)', file_path.split('/')[4])\n",
      "\n",
      "    return match.group(1)\n",
      "\n",
      "def extract_name(file_path):\n",
      "    parts = file_path.split('/')\n",
      "\n",
      "    return parts[6]\n",
      "\n",
      "def get_preceding_30_days(input_date):\n",
      "    date_list = []\n",
      "\n",
      "    # Generate dates for that day and the preceding 30 days\n",
      "    for i in range(31, 0, -1):\n",
      "        # Subtract a day from the date in each iteration\n",
      "        prev_date = input_date - timedelta(days=i)\n",
      "        date_list.append(prev_date.strftime(\"%Y%m%d\"))\n",
      "\n",
      "    return date_list\n",
      "\n",
      "def download_price_data(date_range, generator_name):\n",
      "    print(\"\\n\\nDownloading price data...\\n\", '-'*70, sep='')\n",
      "\n",
      "    if date_range == None:\n",
      "        download_date = datetime.today()\n",
      "        download_date = download_date.strftime(\"%Y%m%d\")\n",
      "\n",
      "        date_range = [download_date]\n",
      "\n",
      "    # Create list of dates to download\n",
      "    dates_to_download = []\n",
      "    for date in date_range:\n",
      "        if os.path.exists(f'{storage_directory}/{date}_{generator_name}.csv'):\n",
      "            print(f'...Price data already downloaded for date: {date}, Generator: {generator_name}')\n",
      "        else:\n",
      "            dates_to_download.append(date)\n",
      "\n",
      "    if len(dates_to_download) != 0:\n",
      "        driver_path = ChromeDriverManager().install()\n",
      "\n",
      "        chrome_options = webdriver.ChromeOptions()\n",
      "        prefs = {'download.default_directory': download_directory}\n",
      "        chrome_options.add_experimental_option('prefs', prefs)\n",
      "\n",
      "        # Initialize the driver, use try except blocks depending on version of selenium installed\n",
      "        try:\n",
      "            # Older selenium version that takes executable path as argument\n",
      "            driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\n",
      "        except:\n",
      "            try:\n",
      "                # For selenium version 3.141.0 or above\n",
      "                driver=webdriver.Chrome(options=chrome_options)\n",
      "            except:\n",
      "                sys.exit(\"Please install correct version of selenium\")\n",
      "\n",
      "        driver.get('http://mis.nyiso.com/public/P-2Blist.htm')\n",
      "        all_links = driver.find_elements(\"xpath\", \"//a[@href]\")\n",
      "\n",
      "        if not os.path.exists(download_directory):\n",
      "            os.makedirs(download_directory)\n",
      "\n",
      "        for date in dates_to_download:\n",
      "            found = False\n",
      "            i = 0\n",
      "\n",
      "            if os.path.exists(f'{storage_directory}/{date}damlbmp_gen.csv'):\n",
      "                print(f'...Price data already downloaded for date: {date}')\n",
      "                found = True\n",
      "\n",
      "            while (not found) and (i < len(all_links)):\n",
      "                link = all_links[i]\n",
      "                href = link.get_attribute('href')\n",
      "\n",
      "                if ('csv' in href) and (date in href) and ('zip' not in href) and ('realtime' not in href):\n",
      "                    link.click()\n",
      "                    time.sleep(3)\n",
      "\n",
      "                    print(download_directory)\n",
      "\n",
      "                    file_name = extract_name(href)\n",
      "                    destination_path = f'{storage_directory}/{file_name}'\n",
      "\n",
      "                    if not os.path.exists(destination_path):\n",
      "                        source_path = f'{download_directory}/{file_name}'\n",
      "\n",
      "                        # Move the file using shutil.move()\n",
      "                        shutil.move(source_path, destination_path)\n",
      "\n",
      "                    found = True\n",
      "\n",
      "                i += 1\n",
      "\n",
      "            if not found:\n",
      "                year_month = date[0:6]\n",
      "                zip_url = f'http://mis.nyiso.com/public/csv/damlbmp/{year_month}01damlbmp_gen_csv.zip'\n",
      "                response = requests.get(zip_url, timeout=10)\n",
      "\n",
      "                # Check if the request was successful (status code 200)\n",
      "                if response.status_code == 200:\n",
      "                    # Save the zip file to the destination folder\n",
      "\n",
      "                    #with open(os.path.join(download_directory, \"month.zip\"), \"wb\") as zip_file:\n",
      "                    with open(os.path.join(storage_directory, \"month.zip\"), \"wb\") as zip_file:\n",
      "                        zip_file.write(response.content)\n",
      "\n",
      "                    # Extract the downloaded zip file\n",
      "                    #with zipfile.ZipFile(os.path.join(download_directory, \"month.zip\"), 'r') as zip_ref:\n",
      "                    with zipfile.ZipFile(os.path.join(storage_directory, \"month.zip\"), 'r') as zip_ref:\n",
      "                       #zip_ref.extractall(download_directory)\n",
      "                        zip_ref.extractall(storage_directory)\n",
      "\n",
      "                    # Remove the downloaded zip file\n",
      "                    #os.remove(os.path.join(download_directory, \"month.zip\"))\n",
      "                    os.remove(os.path.join(storage_directory, \"month.zip\"))\n",
      "                else:\n",
      "                    print(\"Failed to download the zip file\")\n",
      "\n",
      "        # csv_files = [file for file in os.listdir(storage_directory) if file.endswith('.csv')]\n",
      "\n",
      "        driver.quit()\n",
      "\n",
      "        for date in date_range:\n",
      "            file_path = f'{storage_directory}/{date}_{generator_name}.csv'\n",
      "\n",
      "            if not os.path.exists(file_path):\n",
      "                price_df = pd.read_csv(f'{storage_directory}/{date}damlbmp_gen.csv')\n",
      "\n",
      "                price_df = price_df[price_df['Name'] == generator_name][columns].reset_index(drop=True)\n",
      "                price_df = price_df.rename(columns=new_columns)\n",
      "\n",
      "                # Save dfs in data dir\n",
      "                print(f'Saving price data for date: {date}, Generator: {generator_name}')\n",
      "                price_df.to_csv(f'{storage_directory}/{date}_{generator_name}.csv', index=False)\n",
      "\n",
      "    print(\"\\n -- Price data downloaded successfully! -- \\n\\n\")\n",
      "\n",
      "\n",
      "def extract_time_series_prices(date_range, generator, return_df=False, aggregation=None, extended=False):\n",
      "    result = None\n",
      "\n",
      "    dfs = []\n",
      "\n",
      "    for date in date_range:\n",
      "        if extended:\n",
      "            prices_df = pd.read_csv(f'{storage_directory}/extended_time_series/{date[0]}_{date[1]}_{generator}.csv')\n",
      "        else:\n",
      "            prices_df = pd.read_csv(f'{storage_directory}/{date}_{generator}.csv')\n",
      "\n",
      "        dfs.append(prices_df)\n",
      "\n",
      "    prices_df = pd.concat(dfs)\n",
      "\n",
      "    # Ensure that the prices are in order\n",
      "    prices_df = prices_df.sort_values(by='time').reset_index(drop=True)\n",
      "\n",
      "    # Perform any temporal aggregations ?\n",
      "    # if aggregation == 'hourly':\n",
      "    #     # Convert the 'timestamp' column to datetime\n",
      "    #     prices_df['datetime'] = pd.to_datetime(prices_df['time'])\n",
      "\n",
      "    #     # Set the 'timestamp' column as the index\n",
      "    #     prices_df.set_index('datetime', inplace=True)\n",
      "\n",
      "    #     # Resample the DataFrame to hourly frequency and aggregate using the mean\n",
      "    #     hourly_marg_prices = prices_df[['LB_MargPrice']].resample('H').mean()\n",
      "    #     hourly_marg_cost_loss = prices_df[['MargCostLosses']].resample('H').mean()\n",
      "    #     hourly_marg_cost_cong = prices_df[['MargCostCongestion']].resample('H').mean()\n",
      "\n",
      "    #     #Concat\n",
      "    #     hourly_df = pd.concat([hourly_marg_prices, hourly_marg_cost_loss, hourly_marg_cost_cong], axis=1)\n",
      "\n",
      "    #     # Reset the index to include the timestamp as a column\n",
      "    #     hourly_df = hourly_df.reset_index()\n",
      "    #     hourly_df.rename(columns={'datetime': 'time'}, inplace=True)\n",
      "    #     prices_df = hourly_df\n",
      "\n",
      "    if return_df:\n",
      "        result = prices_df\n",
      "    else:\n",
      "        # Extract the prices\n",
      "        times = prices_df['time'].values\n",
      "        prices = prices_df['LB_MargPrice'].values\n",
      "        marg_cost_loss = prices_df['MargCostLosses'].values\n",
      "        marg_cost_cong = prices_df['MargCostCongestion'].values\n",
      "\n",
      "        result = {\n",
      "            'times': times,\n",
      "            'prices': prices,\n",
      "            'marg_cost_loss': marg_cost_loss,\n",
      "            'marg_cost_cong': marg_cost_cong\n",
      "        }\n",
      "\n",
      "    return result\n",
      "\n",
      "\n",
      "def create_extended_time_series(start_date, end_date, generator_name, aggregation=None):\n",
      "    result = None\n",
      "\n",
      "    # Check if already done:\n",
      "    if os.path.exists(f'{storage_directory}/extended_time_series/{start_date}_{end_date}_{generator_name}.csv'):\n",
      "        print(f'Extended time series already created for dates:\\\n",
      "            {start_date} to {end_date}, Generator: {generator_name}')\n",
      "        # Read in and return df\n",
      "        result = pd.read_csv(f'{storage_directory}/extended_time_series/{start_date}_{end_date}_{generator_name}.csv')\n",
      "    else:\n",
      "        # create list of dates between start_date and end_date inclusive\n",
      "        date_list = pd.date_range(start=start_date, end=end_date).tolist()\n",
      "\n",
      "        full_df = None\n",
      "\n",
      "        for date in date_list:\n",
      "            print(\"Fetching price data for date: \", date)\n",
      "            date_formatted = date.strftime(\"%Y%m%d\")\n",
      "\n",
      "            # Try to read it in from data dir\n",
      "            if os.path.exists(f'{storage_directory}/{date_formatted}_{generator_name}.csv'):\n",
      "                price_df = pd.read_csv(f'{storage_directory}/{date_formatted}_{generator_name}.csv')\n",
      "\n",
      "                # Concat it to full_df\n",
      "                if full_df is None:\n",
      "                    full_df = price_df\n",
      "                else:\n",
      "                    full_df = pd.concat([full_df, price_df], axis=0)\n",
      "\n",
      "            # Try to read it in from downloads\n",
      "            if os.path.exists(f'{storage_directory}/downloads/{date_formatted}realtime_gen.csv'):\n",
      "                price_df = pd.read_csv(f'{storage_directory}/downloads/{date_formatted}realtime_gen.csv')\n",
      "                price_df = price_df[price_df['Name'] == generator_name][columns].reset_index(drop=True)\n",
      "\n",
      "                price_df = price_df.rename(columns=new_columns)\n",
      "\n",
      "                price_df.to_csv(f'{storage_directory}/{date_formatted}_{generator_name}.csv', index=False)\n",
      "\n",
      "                # Concat it to full_df\n",
      "                if full_df is None:\n",
      "                    full_df = price_df\n",
      "                else:\n",
      "                    full_df = pd.concat([full_df, price_df], axis=0)\n",
      "\n",
      "        # Save extended time series\n",
      "        result = full_df.to_csv(f'Data/extended_time_series/{start_date}_{end_date}_{generator_name}.csv', index=False)\n",
      "\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "import re\n",
      "import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import gurobipy as gp\n",
      "import sys\n",
      "from gurobipy import GRB\n",
      "from datetime import datetime\n",
      "from selenium import webdriver\n",
      "from webdriver_manager.chrome import ChromeDriverManager\n",
      "\n",
      "from web_scrape_price_data import extract_date, download_price_data, extract_time_series_prices\n",
      "from make_plots import plot_price_time_series\n",
      "\n",
      "# Set parameters for the model\n",
      "\n",
      "# OPTIGUIDE DATA CODE GOES HERE\n",
      "\n",
      "def create_model(parameters): # num_markets is going to be 1 for the time being\n",
      "    name = parameters['name']\n",
      "    generator_name = parameters['generator_name']\n",
      "    date_range = parameters['date_range']\n",
      "    num_markets = parameters['num_markets'] # not really used as of now\n",
      "    battery_types = parameters['battery_types']\n",
      "    battery_types_used = parameters['battery_types_used']\n",
      "    battery_counts = parameters['battery_counts']\n",
      "    warehouse_data = parameters['warehouse_data']\n",
      "    warehouses_used = parameters['warehouses_used']\n",
      "    carry_over = parameters['carry_over']\n",
      "\n",
      "    # Container to fill with prices and dates to pass out of the function\n",
      "    constraint_params = {}\n",
      "\n",
      "    # placeholder\n",
      "    if date_range is None:\n",
      "        start_date = datetime.today()\n",
      "        start_date = start_date.strftime(\"%Y%m%d\")\n",
      "        date_range = [start_date]\n",
      "\n",
      "    # Download data\n",
      "    download_price_data(date_range, generator_name)\n",
      "\n",
      "    # Plot prices time series\n",
      "    # plot_price_time_series(date_range, generator_name)\n",
      "\n",
      "    # Extract time series of prices in a list for Gurobi\n",
      "    prices_dict = extract_time_series_prices(date_range, generator_name, aggregation=None)\n",
      "    price_times = prices_dict['times']\n",
      "\n",
      "    prices = prices_dict['prices']\n",
      "\n",
      "    model = gp.Model(name)\n",
      "\n",
      "    num_periods = len(prices)\n",
      "    parameters['num_periods'] = num_periods\n",
      "\n",
      "    periods = range(num_periods)\n",
      "    # markets = range(num_markets)\n",
      "\n",
      "    decision_var_dict = {}\n",
      "\n",
      "    if battery_counts is None:\n",
      "        decision_var_dict['battery_counts'] = {}\n",
      "\n",
      "    for battery_type in battery_types_used:\n",
      "        for key in [f'{battery_type}_buy', f'{battery_type}_sell']:\n",
      "            decision_var_dict[key] = model.addVars(num_periods, vtype=GRB.CONTINUOUS, name=key, lb=0) # num_markets, \n",
      "\n",
      "    objs = []\n",
      "    total_area_needed = 0\n",
      "\n",
      "    for battery_type in battery_types_used:\n",
      "        battery = battery_types[battery_type]\n",
      "\n",
      "        buy = decision_var_dict[f'{battery_type}_buy']\n",
      "        sell = decision_var_dict[f'{battery_type}_sell']\n",
      "        capacity = battery['capacity']\n",
      "        charge_loss = battery['charge_loss']\n",
      "        max_charge = battery['max_charge']\n",
      "        max_discharge = battery['max_discharge']\n",
      "        size = battery['size']\n",
      "        cost = battery['cost']\n",
      "\n",
      "        if battery_counts is None:\n",
      "            battery_count = model.addVar(vtype=GRB.INTEGER, name=f'Number of {battery_type} batteries', lb=0)\n",
      "            decision_var_dict['battery_counts'][battery_type] = battery_count\n",
      "\n",
      "            objs.append(cost * battery_count * -1)\n",
      "        else:\n",
      "            battery_count = battery_counts[battery_type]\n",
      "\n",
      "        for p in range(num_periods):\n",
      "            current_level = gp.quicksum(charge_loss * buy[p_] - sell[p_] for p_ in range(p + 1)) # for i in markets\n",
      "\n",
      "            if not carry_over and p % 24 == 0:\n",
      "                model.addConstr(current_level <= 0, 'CarryOverConstraint')\n",
      "\n",
      "            # for i in markets:\n",
      "            model.addConstr(current_level <= capacity * battery_count, f'CapacityConstraint_period_{p+1}')\n",
      "            model.addConstr(current_level >= 0, f'SupplyConstraint_period_{p+1}')\n",
      "            model.addConstr(buy[p] * charge_loss <= max_charge, f'ChargeConstraint_period_{p+1}')\n",
      "            model.addConstr(sell[p] <= max_discharge, f'DischargeConstraint_period_{p+1}')\n",
      "\n",
      "        model.update()\n",
      "\n",
      "        objs = objs + [prices[p] * sell[p] - prices[p] * buy[p] for p in periods] #  for i in markets\n",
      "\n",
      "        total_area_needed += battery_count * size\n",
      "\n",
      "    if warehouses_used is None:\n",
      "        warehouses_used = model.addVars(len(warehouse_data), vtype=GRB.BINARY, name=f'Number of warehouses')\n",
      "        decision_var_dict['warehouses_used'] = warehouses_used\n",
      "\n",
      "        model.update()\n",
      "\n",
      "        model.addConstr(\n",
      "            gp.quicksum(\n",
      "                warehouse_data[i]['area'] * warehouses_used[i] for i, warehouse in enumerate(warehouse_data)\n",
      "            ) >= total_area_needed,\n",
      "            name=\"Area_constraint\"\n",
      "        )\n",
      "\n",
      "        objs = objs + [warehouse_data[i]['cost'] * warehouses_used[i] * -1 for i, warehouse in enumerate(warehouse_data)]\n",
      "\n",
      "    model.update()\n",
      "\n",
      "    model.setObjective(\n",
      "        gp.quicksum(objs),\n",
      "        GRB.MAXIMIZE\n",
      "    )\n",
      "    # OPTIGUIDE CONSTRAINT CODE GOES HERE\n",
      "\n",
      "    constraint_params['price_times'] = price_times\n",
      "    constraint_params['prices'] = prices_dict['prices']\n",
      "\n",
      "    return [model, decision_var_dict, constraint_params]\n",
      "\n",
      "\n",
      "# Run the model\n",
      "def run(parameters, print_results=False):\n",
      "    battery_types_used = parameters['battery_types_used']\n",
      "\n",
      "    # Create model\n",
      "    [model, decision_var_dict, constraint_params] = create_model(parameters)\n",
      "\n",
      "    # Run model\n",
      "    model.optimize()\n",
      "\n",
      "    if model.status == GRB.OPTIMAL:\n",
      "        # Unpack results\n",
      "        model_results = {}\n",
      "\n",
      "        model_results['num_periods'] = parameters['num_periods']\n",
      "        # model_results['num_markets'] = parameters['num_markets']\n",
      "        model_results['buy_ts'] = {battery_type: [] for battery_type in battery_types_used}\n",
      "        model_results['sell_ts'] = {battery_type: [] for battery_type in battery_types_used}\n",
      "        model_results['time'] = list(range(parameters['num_periods']))\n",
      "        model_results['total_profit'] = model.objVal\n",
      "\n",
      "        if print_results:\n",
      "            print(\"\\nOptimal Solution:\")\n",
      "\n",
      "        for p in range(model_results['num_periods']):\n",
      "            if print_results:\n",
      "                print(f\"\\nPeriod {p + 1}:\")\n",
      "\n",
      "            for battery_type in battery_types_used:\n",
      "                buy = decision_var_dict[f'{battery_type}_buy']\n",
      "                sell = decision_var_dict[f'{battery_type}_sell']\n",
      "\n",
      "                if print_results:\n",
      "                    print(f\"\\nFor Battery Type: {battery_type}:\")\n",
      "\n",
      "                # for i in range(model_results['num_markets']):\n",
      "                if print_results:\n",
      "                    print(f\"Buy {buy[p].x}\")\n",
      "                    print(f\"Sell {sell[p].x}\")\n",
      "\n",
      "                model_results['buy_ts'][battery_type].append(buy[p].x)\n",
      "                model_results['sell_ts'][battery_type].append(sell[p].x)\n",
      "\n",
      "        if print_results:\n",
      "            print(f\"\\nTotal Profit: {model.objVal}\")\n",
      "\n",
      "    else:\n",
      "        model_results = None\n",
      "        print(\"No solution found\")\n",
      "\n",
      "    if parameters['battery_counts'] is None:\n",
      "        decision_var_dict['battery_counts'] = {key: battery_count.x for key, battery_count in decision_var_dict['battery_counts'].items()}\n",
      "\n",
      "    return [model, decision_var_dict, model_results, constraint_params]\n",
      "from run_model import run\n",
      "from make_plots import plot_result_time_series, plot_waterfall_chart\n",
      "from web_scrape_price_data import get_preceding_30_days\n",
      "from datetime import datetime, timedelta\n",
      "import time\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "parameters = {\n",
      "    'name': 'ElectricityArbitrage',\n",
      "    'generator_name': 'ADK HUDSON___FALLS',\n",
      "    'date_range': None,\n",
      "    'num_markets': 1,\n",
      "    'battery_types': {\n",
      "        'lithium': {\n",
      "            'size': 1,\n",
      "            'capacity': 100,\n",
      "            'charge_loss': 0.95,\n",
      "            'max_charge': 50,\n",
      "            'max_discharge': 50,\n",
      "            'cost': 200\n",
      "        },\n",
      "        'lead': {\n",
      "            'size': 0.8,\n",
      "            'capacity': 200,\n",
      "            'charge_loss': 0.90,\n",
      "            'max_charge': 25,\n",
      "            'max_discharge': 25,\n",
      "            'cost': 100\n",
      "        },\n",
      "        'palladium': {\n",
      "            'size': 3,\n",
      "            'capacity': 50,\n",
      "            'charge_loss': 0.85,\n",
      "            'max_charge': 100,\n",
      "            'max_discharge': 100,\n",
      "            'cost': 150\n",
      "        }\n",
      "    },\n",
      "    'battery_types_used': ['lithium', 'lead', 'palladium'],\n",
      "    'battery_counts': None,\n",
      "    'warehouse_data': [\n",
      "        {'area': 100, 'cost': 5000},\n",
      "        {'area': 100, 'cost': 10000},\n",
      "        {'area': 100, 'cost': 20000},\n",
      "        {'area': 100, 'cost': 50000},\n",
      "        {'area': 100, 'cost': 100000}\n",
      "    ],\n",
      "    'warehouses_used': None,\n",
      "    'carry_over': False\n",
      "}\n",
      "\n",
      "# Battery numbers\n",
      "def stage_one(start_date, parameters):\n",
      "    date_range = get_preceding_30_days(start_date)\n",
      "    parameters['date_range'] = date_range\n",
      "\n",
      "    return run(parameters)\n",
      "\n",
      "def stage_two(start_date, parameters, decision_var_dict):\n",
      "    parameters['battery_counts'] = decision_var_dict['battery_counts']\n",
      "    parameters['warehouses_used'] = 'set'\n",
      "    parameters['date_range'] = [start_date.strftime(\"%Y%m%d\")]\n",
      "\n",
      "    daily_profits = []\n",
      "    start_date = datetime.today() - timedelta(days=1)\n",
      "\n",
      "    for start_date in get_preceding_30_days(start_date):\n",
      "        parameters['date_range'] = [start_date]\n",
      "\n",
      "        [model, _, _, _] = run(parameters)\n",
      "\n",
      "        daily_profits.append(model.objVal)\n",
      "\n",
      "    return daily_profits\n",
      "\n",
      "start_date = datetime.today() - timedelta(days=31)\n",
      "\n",
      "model, decision_var_dict, model_results, constraint_params = stage_one(start_date, parameters)\n",
      "\n",
      "# plot_result_time_series(model, decision_var_dict, model_results, constraint_params)\n",
      "\n",
      "daily_profits = stage_two(start_date, parameters, decision_var_dict)\n",
      "\n",
      "print(daily_profits)\n",
      "\n",
      "time.sleep(5)\n",
      "\n",
      "# Plot DVs\n",
      "# plot_result_time_series(model, decision_var_dict, model_results, constraint_params)\n",
      "\n",
      "# Plot waterfall profits\n",
      "plot_waterfall_chart( parameters, daily_profits )\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "import os\n",
      "import re\n",
      "import sys\n",
      "import time\n",
      "import shutil\n",
      "import zipfile\n",
      "import requests\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import gurobipy as gp\n",
      "from selenium import webdriver\n",
      "from datetime import datetime, timedelta\n",
      "from webdriver_manager.chrome import ChromeDriverManager\n",
      "\n",
      "columns = ['Time Stamp', 'LBMP ($/MWHr)', 'Marginal Cost Losses ($/MWHr)', 'Marginal Cost Congestion ($/MWHr)']\n",
      "new_columns = {\n",
      "    'Time Stamp': 'time',\n",
      "    'LBMP ($/MWHr)': 'LB_MargPrice',\n",
      "    'Marginal Cost Losses ($/MWHr)': 'MargCostLosses',\n",
      "    'Marginal Cost Congestion ($/MWHr)': 'MargCostCongestion'\n",
      "}\n",
      "\n",
      "home_dir = os.path.expanduser(\"~\")\n",
      "download_directory = os.path.join(home_dir, 'Downloads_CSV')\n",
      "storage_directory = 'Data'\n",
      "\n",
      "def extract_date(file_path):\n",
      "    match = re.match(r'^(\\d+)', file_path.split('/')[4])\n",
      "\n",
      "    return match.group(1)\n",
      "\n",
      "def extract_name(file_path):\n",
      "    parts = file_path.split('/')\n",
      "\n",
      "    return parts[6]\n",
      "\n",
      "def get_preceding_30_days(input_date):\n",
      "    date_list = []\n",
      "\n",
      "    # Generate dates for that day and the preceding 30 days\n",
      "    for i in range(31, 0, -1):\n",
      "        # Subtract a day from the date in each iteration\n",
      "        prev_date = input_date - timedelta(days=i)\n",
      "        date_list.append(prev_date.strftime(\"%Y%m%d\"))\n",
      "\n",
      "    return date_list\n",
      "\n",
      "def download_price_data(date_range, generator_name):\n",
      "    print(\"\\n\\nDownloading price data...\\n\", '-'*70, sep='')\n",
      "\n",
      "    if date_range == None:\n",
      "        download_date = datetime.today()\n",
      "        download_date = download_date.strftime(\"%Y%m%d\")\n",
      "\n",
      "        date_range = [download_date]\n",
      "\n",
      "    # Create list of dates to download\n",
      "    dates_to_download = []\n",
      "    for date in date_range:\n",
      "        if os.path.exists(f'{storage_directory}/{date}_{generator_name}.csv'):\n",
      "            print(f'...Price data already downloaded for date: {date}, Generator: {generator_name}')\n",
      "        else:\n",
      "            dates_to_download.append(date)\n",
      "\n",
      "    if len(dates_to_download) != 0:\n",
      "        driver_path = ChromeDriverManager().install()\n",
      "\n",
      "        chrome_options = webdriver.ChromeOptions()\n",
      "        prefs = {'download.default_directory': download_directory}\n",
      "        chrome_options.add_experimental_option('prefs', prefs)\n",
      "\n",
      "        # Initialize the driver, use try except blocks depending on version of selenium installed\n",
      "        try:\n",
      "            # Older selenium version that takes executable path as argument\n",
      "            driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\n",
      "        except:\n",
      "            try:\n",
      "                # For selenium version 3.141.0 or above\n",
      "                driver=webdriver.Chrome(options=chrome_options)\n",
      "            except:\n",
      "                sys.exit(\"Please install correct version of selenium\")\n",
      "\n",
      "        driver.get('http://mis.nyiso.com/public/P-2Blist.htm')\n",
      "        all_links = driver.find_elements(\"xpath\", \"//a[@href]\")\n",
      "\n",
      "        if not os.path.exists(download_directory):\n",
      "            os.makedirs(download_directory)\n",
      "\n",
      "        for date in dates_to_download:\n",
      "            found = False\n",
      "            i = 0\n",
      "\n",
      "            if os.path.exists(f'{storage_directory}/{date}damlbmp_gen.csv'):\n",
      "                print(f'...Price data already downloaded for date: {date}')\n",
      "                found = True\n",
      "\n",
      "            while (not found) and (i < len(all_links)):\n",
      "                link = all_links[i]\n",
      "                href = link.get_attribute('href')\n",
      "\n",
      "                if ('csv' in href) and (date in href) and ('zip' not in href) and ('realtime' not in href):\n",
      "                    link.click()\n",
      "                    time.sleep(3)\n",
      "\n",
      "                    print(download_directory)\n",
      "\n",
      "                    file_name = extract_name(href)\n",
      "                    destination_path = f'{storage_directory}/{file_name}'\n",
      "\n",
      "                    if not os.path.exists(destination_path):\n",
      "                        source_path = f'{download_directory}/{file_name}'\n",
      "\n",
      "                        # Move the file using shutil.move()\n",
      "                        shutil.move(source_path, destination_path)\n",
      "\n",
      "                    found = True\n",
      "\n",
      "                i += 1\n",
      "\n",
      "            if not found:\n",
      "                year_month = date[0:6]\n",
      "                zip_url = f'http://mis.nyiso.com/public/csv/damlbmp/{year_month}01damlbmp_gen_csv.zip'\n",
      "                response = requests.get(zip_url, timeout=10)\n",
      "\n",
      "                # Check if the request was successful (status code 200)\n",
      "                if response.status_code == 200:\n",
      "                    # Save the zip file to the destination folder\n",
      "\n",
      "                    #with open(os.path.join(download_directory, \"month.zip\"), \"wb\") as zip_file:\n",
      "                    with open(os.path.join(storage_directory, \"month.zip\"), \"wb\") as zip_file:\n",
      "                        zip_file.write(response.content)\n",
      "\n",
      "                    # Extract the downloaded zip file\n",
      "                    #with zipfile.ZipFile(os.path.join(download_directory, \"month.zip\"), 'r') as zip_ref:\n",
      "                    with zipfile.ZipFile(os.path.join(storage_directory, \"month.zip\"), 'r') as zip_ref:\n",
      "                       #zip_ref.extractall(download_directory)\n",
      "                        zip_ref.extractall(storage_directory)\n",
      "\n",
      "                    # Remove the downloaded zip file\n",
      "                    #os.remove(os.path.join(download_directory, \"month.zip\"))\n",
      "                    os.remove(os.path.join(storage_directory, \"month.zip\"))\n",
      "                else:\n",
      "                    print(\"Failed to download the zip file\")\n",
      "\n",
      "        # csv_files = [file for file in os.listdir(storage_directory) if file.endswith('.csv')]\n",
      "\n",
      "        driver.quit()\n",
      "\n",
      "        for date in date_range:\n",
      "            file_path = f'{storage_directory}/{date}_{generator_name}.csv'\n",
      "\n",
      "            if not os.path.exists(file_path):\n",
      "                price_df = pd.read_csv(f'{storage_directory}/{date}damlbmp_gen.csv')\n",
      "\n",
      "                price_df = price_df[price_df['Name'] == generator_name][columns].reset_index(drop=True)\n",
      "                price_df = price_df.rename(columns=new_columns)\n",
      "\n",
      "                # Save dfs in data dir\n",
      "                print(f'Saving price data for date: {date}, Generator: {generator_name}')\n",
      "                price_df.to_csv(f'{storage_directory}/{date}_{generator_name}.csv', index=False)\n",
      "\n",
      "    print(\"\\n -- Price data downloaded successfully! -- \\n\\n\")\n",
      "\n",
      "\n",
      "def extract_time_series_prices(date_range, generator, return_df=False, aggregation=None, extended=False):\n",
      "    result = None\n",
      "\n",
      "    dfs = []\n",
      "\n",
      "    for date in date_range:\n",
      "        if extended:\n",
      "            prices_df = pd.read_csv(f'{storage_directory}/extended_time_series/{date[0]}_{date[1]}_{generator}.csv')\n",
      "        else:\n",
      "            prices_df = pd.read_csv(f'{storage_directory}/{date}_{generator}.csv')\n",
      "\n",
      "        dfs.append(prices_df)\n",
      "\n",
      "    prices_df = pd.concat(dfs)\n",
      "\n",
      "    # Ensure that the prices are in order\n",
      "    prices_df = prices_df.sort_values(by='time').reset_index(drop=True)\n",
      "\n",
      "    # Perform any temporal aggregations ?\n",
      "    # if aggregation == 'hourly':\n",
      "    #     # Convert the 'timestamp' column to datetime\n",
      "    #     prices_df['datetime'] = pd.to_datetime(prices_df['time'])\n",
      "\n",
      "    #     # Set the 'timestamp' column as the index\n",
      "    #     prices_df.set_index('datetime', inplace=True)\n",
      "\n",
      "    #     # Resample the DataFrame to hourly frequency and aggregate using the mean\n",
      "    #     hourly_marg_prices = prices_df[['LB_MargPrice']].resample('H').mean()\n",
      "    #     hourly_marg_cost_loss = prices_df[['MargCostLosses']].resample('H').mean()\n",
      "    #     hourly_marg_cost_cong = prices_df[['MargCostCongestion']].resample('H').mean()\n",
      "\n",
      "    #     #Concat\n",
      "    #     hourly_df = pd.concat([hourly_marg_prices, hourly_marg_cost_loss, hourly_marg_cost_cong], axis=1)\n",
      "\n",
      "    #     # Reset the index to include the timestamp as a column\n",
      "    #     hourly_df = hourly_df.reset_index()\n",
      "    #     hourly_df.rename(columns={'datetime': 'time'}, inplace=True)\n",
      "    #     prices_df = hourly_df\n",
      "\n",
      "    if return_df:\n",
      "        result = prices_df\n",
      "    else:\n",
      "        # Extract the prices\n",
      "        times = prices_df['time'].values\n",
      "        prices = prices_df['LB_MargPrice'].values\n",
      "        marg_cost_loss = prices_df['MargCostLosses'].values\n",
      "        marg_cost_cong = prices_df['MargCostCongestion'].values\n",
      "\n",
      "        result = {\n",
      "            'times': times,\n",
      "            'prices': prices,\n",
      "            'marg_cost_loss': marg_cost_loss,\n",
      "            'marg_cost_cong': marg_cost_cong\n",
      "        }\n",
      "\n",
      "    return result\n",
      "\n",
      "\n",
      "def create_extended_time_series(start_date, end_date, generator_name, aggregation=None):\n",
      "    result = None\n",
      "\n",
      "    # Check if already done:\n",
      "    if os.path.exists(f'{storage_directory}/extended_time_series/{start_date}_{end_date}_{generator_name}.csv'):\n",
      "        print(f'Extended time series already created for dates:\\\n",
      "            {start_date} to {end_date}, Generator: {generator_name}')\n",
      "        # Read in and return df\n",
      "        result = pd.read_csv(f'{storage_directory}/extended_time_series/{start_date}_{end_date}_{generator_name}.csv')\n",
      "    else:\n",
      "        # create list of dates between start_date and end_date inclusive\n",
      "        date_list = pd.date_range(start=start_date, end=end_date).tolist()\n",
      "\n",
      "        full_df = None\n",
      "\n",
      "        for date in date_list:\n",
      "            print(\"Fetching price data for date: \", date)\n",
      "            date_formatted = date.strftime(\"%Y%m%d\")\n",
      "\n",
      "            # Try to read it in from data dir\n",
      "            if os.path.exists(f'{storage_directory}/{date_formatted}_{generator_name}.csv'):\n",
      "                price_df = pd.read_csv(f'{storage_directory}/{date_formatted}_{generator_name}.csv')\n",
      "\n",
      "                # Concat it to full_df\n",
      "                if full_df is None:\n",
      "                    full_df = price_df\n",
      "                else:\n",
      "                    full_df = pd.concat([full_df, price_df], axis=0)\n",
      "\n",
      "            # Try to read it in from downloads\n",
      "            if os.path.exists(f'{storage_directory}/downloads/{date_formatted}realtime_gen.csv'):\n",
      "                price_df = pd.read_csv(f'{storage_directory}/downloads/{date_formatted}realtime_gen.csv')\n",
      "                price_df = price_df[price_df['Name'] == generator_name][columns].reset_index(drop=True)\n",
      "\n",
      "                price_df = price_df.rename(columns=new_columns)\n",
      "\n",
      "                price_df.to_csv(f'{storage_directory}/{date_formatted}_{generator_name}.csv', index=False)\n",
      "\n",
      "                # Concat it to full_df\n",
      "                if full_df is None:\n",
      "                    full_df = price_df\n",
      "                else:\n",
      "                    full_df = pd.concat([full_df, price_df], axis=0)\n",
      "\n",
      "        # Save extended time series\n",
      "        result = full_df.to_csv(f'Data/extended_time_series/{start_date}_{end_date}_{generator_name}.csv', index=False)\n",
      "\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "import re\n",
      "import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import gurobipy as gp\n",
      "import sys\n",
      "from gurobipy import GRB\n",
      "from datetime import datetime\n",
      "from selenium import webdriver\n",
      "from webdriver_manager.chrome import ChromeDriverManager\n",
      "\n",
      "from web_scrape_price_data import extract_date, download_price_data, extract_time_series_prices\n",
      "from make_plots import plot_price_time_series\n",
      "\n",
      "# Set parameters for the model\n",
      "\n",
      "# OPTIGUIDE DATA CODE GOES HERE\n",
      "\n",
      "def create_model(parameters): # num_markets is going to be 1 for the time being\n",
      "    name = parameters['name']\n",
      "    generator_name = parameters['generator_name']\n",
      "    date_range = parameters['date_range']\n",
      "    num_markets = parameters['num_markets'] # not really used as of now\n",
      "    battery_types = parameters['battery_types']\n",
      "    battery_types_used = parameters['battery_types_used']\n",
      "    battery_counts = parameters['battery_counts']\n",
      "    warehouse_data = parameters['warehouse_data']\n",
      "    warehouses_used = parameters['warehouses_used']\n",
      "    carry_over = parameters['carry_over']\n",
      "\n",
      "    # Container to fill with prices and dates to pass out of the function\n",
      "    constraint_params = {}\n",
      "\n",
      "    # placeholder\n",
      "    if date_range is None:\n",
      "        start_date = datetime.today()\n",
      "        start_date = start_date.strftime(\"%Y%m%d\")\n",
      "        date_range = [start_date]\n",
      "\n",
      "    # Download data\n",
      "    download_price_data(date_range, generator_name)\n",
      "\n",
      "    # Plot prices time series\n",
      "    # plot_price_time_series(date_range, generator_name)\n",
      "\n",
      "    # Extract time series of prices in a list for Gurobi\n",
      "    prices_dict = extract_time_series_prices(date_range, generator_name, aggregation=None)\n",
      "    price_times = prices_dict['times']\n",
      "\n",
      "    prices = prices_dict['prices']\n",
      "\n",
      "    model = gp.Model(name)\n",
      "\n",
      "    num_periods = len(prices)\n",
      "    parameters['num_periods'] = num_periods\n",
      "\n",
      "    periods = range(num_periods)\n",
      "    # markets = range(num_markets)\n",
      "\n",
      "    decision_var_dict = {}\n",
      "\n",
      "    if battery_counts is None:\n",
      "        decision_var_dict['battery_counts'] = {}\n",
      "\n",
      "    for battery_type in battery_types_used:\n",
      "        for key in [f'{battery_type}_buy', f'{battery_type}_sell']:\n",
      "            decision_var_dict[key] = model.addVars(num_periods, vtype=GRB.CONTINUOUS, name=key, lb=0) # num_markets, \n",
      "\n",
      "    objs = []\n",
      "    total_area_needed = 0\n",
      "\n",
      "    for battery_type in battery_types_used:\n",
      "        battery = battery_types[battery_type]\n",
      "\n",
      "        buy = decision_var_dict[f'{battery_type}_buy']\n",
      "        sell = decision_var_dict[f'{battery_type}_sell']\n",
      "        capacity = battery['capacity']\n",
      "        charge_loss = battery['charge_loss']\n",
      "        max_charge = battery['max_charge']\n",
      "        max_discharge = battery['max_discharge']\n",
      "        size = battery['size']\n",
      "        cost = battery['cost']\n",
      "\n",
      "        if battery_counts is None:\n",
      "            battery_count = model.addVar(vtype=GRB.INTEGER, name=f'Number of {battery_type} batteries', lb=0)\n",
      "            decision_var_dict['battery_counts'][battery_type] = battery_count\n",
      "\n",
      "            objs.append(cost * battery_count * -1)\n",
      "        else:\n",
      "            battery_count = battery_counts[battery_type]\n",
      "\n",
      "        for p in range(num_periods):\n",
      "            current_level = gp.quicksum(charge_loss * buy[p_] - sell[p_] for p_ in range(p + 1)) # for i in markets\n",
      "\n",
      "            if not carry_over and p % 24 == 0:\n",
      "                model.addConstr(current_level <= 0, 'CarryOverConstraint')\n",
      "\n",
      "            # for i in markets:\n",
      "            model.addConstr(current_level <= capacity * battery_count, f'CapacityConstraint_period_{p+1}')\n",
      "            model.addConstr(current_level >= 0, f'SupplyConstraint_period_{p+1}')\n",
      "            model.addConstr(buy[p] * charge_loss <= max_charge, f'ChargeConstraint_period_{p+1}')\n",
      "            model.addConstr(sell[p] <= max_discharge, f'DischargeConstraint_period_{p+1}')\n",
      "\n",
      "        model.update()\n",
      "\n",
      "        objs = objs + [prices[p] * sell[p] - prices[p] * buy[p] for p in periods] #  for i in markets\n",
      "\n",
      "        total_area_needed += battery_count * size\n",
      "\n",
      "    if warehouses_used is None:\n",
      "        warehouses_used = model.addVars(len(warehouse_data), vtype=GRB.BINARY, name=f'Number of warehouses')\n",
      "        decision_var_dict['warehouses_used'] = warehouses_used\n",
      "\n",
      "        model.update()\n",
      "\n",
      "        model.addConstr(\n",
      "            gp.quicksum(\n",
      "                warehouse_data[i]['area'] * warehouses_used[i] for i, warehouse in enumerate(warehouse_data)\n",
      "            ) >= total_area_needed,\n",
      "            name=\"Area_constraint\"\n",
      "        )\n",
      "\n",
      "        objs = objs + [warehouse_data[i]['cost'] * warehouses_used[i] * -1 for i, warehouse in enumerate(warehouse_data)]\n",
      "\n",
      "    model.update()\n",
      "\n",
      "    model.setObjective(\n",
      "        gp.quicksum(objs),\n",
      "        GRB.MAXIMIZE\n",
      "    )\n",
      "    # OPTIGUIDE CONSTRAINT CODE GOES HERE\n",
      "\n",
      "    constraint_params['price_times'] = price_times\n",
      "    constraint_params['prices'] = prices_dict['prices']\n",
      "\n",
      "    return [model, decision_var_dict, constraint_params]\n",
      "\n",
      "\n",
      "# Run the model\n",
      "def run(parameters, print_results=False):\n",
      "    battery_types_used = parameters['battery_types_used']\n",
      "\n",
      "    # Create model\n",
      "    [model, decision_var_dict, constraint_params] = create_model(parameters)\n",
      "\n",
      "    # Run model\n",
      "    model.optimize()\n",
      "\n",
      "    if model.status == GRB.OPTIMAL:\n",
      "        # Unpack results\n",
      "        model_results = {}\n",
      "\n",
      "        model_results['num_periods'] = parameters['num_periods']\n",
      "        # model_results['num_markets'] = parameters['num_markets']\n",
      "        model_results['buy_ts'] = {battery_type: [] for battery_type in battery_types_used}\n",
      "        model_results['sell_ts'] = {battery_type: [] for battery_type in battery_types_used}\n",
      "        model_results['time'] = list(range(parameters['num_periods']))\n",
      "        model_results['total_profit'] = model.objVal\n",
      "\n",
      "        if print_results:\n",
      "            print(\"\\nOptimal Solution:\")\n",
      "\n",
      "        for p in range(model_results['num_periods']):\n",
      "            if print_results:\n",
      "                print(f\"\\nPeriod {p + 1}:\")\n",
      "\n",
      "            for battery_type in battery_types_used:\n",
      "                buy = decision_var_dict[f'{battery_type}_buy']\n",
      "                sell = decision_var_dict[f'{battery_type}_sell']\n",
      "\n",
      "                if print_results:\n",
      "                    print(f\"\\nFor Battery Type: {battery_type}:\")\n",
      "\n",
      "                # for i in range(model_results['num_markets']):\n",
      "                if print_results:\n",
      "                    print(f\"Buy {buy[p].x}\")\n",
      "                    print(f\"Sell {sell[p].x}\")\n",
      "\n",
      "                model_results['buy_ts'][battery_type].append(buy[p].x)\n",
      "                model_results['sell_ts'][battery_type].append(sell[p].x)\n",
      "\n",
      "        if print_results:\n",
      "            print(f\"\\nTotal Profit: {model.objVal}\")\n",
      "\n",
      "    else:\n",
      "        model_results = None\n",
      "        print(\"No solution found\")\n",
      "\n",
      "    if parameters['battery_counts'] is None:\n",
      "        decision_var_dict['battery_counts'] = {key: battery_count.x for key, battery_count in decision_var_dict['battery_counts'].items()}\n",
      "\n",
      "    return [model, decision_var_dict, model_results, constraint_params]\n",
      "from run_model import run\n",
      "from make_plots import plot_result_time_series, plot_waterfall_chart\n",
      "from web_scrape_price_data import get_preceding_30_days\n",
      "from datetime import datetime, timedelta\n",
      "import time\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "parameters = {\n",
      "    'name': 'ElectricityArbitrage',\n",
      "    'generator_name': 'ADK HUDSON___FALLS',\n",
      "    'date_range': None,\n",
      "    'num_markets': 1,\n",
      "    'battery_types': {\n",
      "        'lithium': {\n",
      "            'size': 1,\n",
      "            'capacity': 100,\n",
      "            'charge_loss': 0.95,\n",
      "            'max_charge': 50,\n",
      "            'max_discharge': 50,\n",
      "            'cost': 200\n",
      "        },\n",
      "        'lead': {\n",
      "            'size': 0.8,\n",
      "            'capacity': 200,\n",
      "            'charge_loss': 0.90,\n",
      "            'max_charge': 25,\n",
      "            'max_discharge': 25,\n",
      "            'cost': 100\n",
      "        },\n",
      "        'palladium': {\n",
      "            'size': 3,\n",
      "            'capacity': 50,\n",
      "            'charge_loss': 0.85,\n",
      "            'max_charge': 100,\n",
      "            'max_discharge': 100,\n",
      "            'cost': 150\n",
      "        }\n",
      "    },\n",
      "    'battery_types_used': ['lithium', 'lead', 'palladium'],\n",
      "    'battery_counts': None,\n",
      "    'warehouse_data': [\n",
      "        {'area': 100, 'cost': 5000},\n",
      "        {'area': 100, 'cost': 10000},\n",
      "        {'area': 100, 'cost': 20000},\n",
      "        {'area': 100, 'cost': 50000},\n",
      "        {'area': 100, 'cost': 100000}\n",
      "    ],\n",
      "    'warehouses_used': None,\n",
      "    'carry_over': False\n",
      "}\n",
      "\n",
      "# Battery numbers\n",
      "def stage_one(start_date, parameters):\n",
      "    date_range = get_preceding_30_days(start_date)\n",
      "    parameters['date_range'] = date_range\n",
      "\n",
      "    return run(parameters)\n",
      "\n",
      "def stage_two(start_date, parameters, decision_var_dict):\n",
      "    parameters['battery_counts'] = decision_var_dict['battery_counts']\n",
      "    parameters['warehouses_used'] = 'set'\n",
      "    parameters['date_range'] = [start_date.strftime(\"%Y%m%d\")]\n",
      "\n",
      "    daily_profits = []\n",
      "    start_date = datetime.today() - timedelta(days=1)\n",
      "\n",
      "    for start_date in get_preceding_30_days(start_date):\n",
      "        parameters['date_range'] = [start_date]\n",
      "\n",
      "        [model, _, _, _] = run(parameters)\n",
      "\n",
      "        daily_profits.append(model.objVal)\n",
      "\n",
      "    return daily_profits\n",
      "\n",
      "start_date = datetime.today() - timedelta(days=31)\n",
      "\n",
      "model, decision_var_dict, model_results, constraint_params = stage_one(start_date, parameters)\n",
      "\n",
      "# plot_result_time_series(model, decision_var_dict, model_results, constraint_params)\n",
      "\n",
      "daily_profits = stage_two(start_date, parameters, decision_var_dict)\n",
      "\n",
      "print(daily_profits)\n",
      "\n",
      "time.sleep(5)\n",
      "\n",
      "# Plot DVs\n",
      "# plot_result_time_series(model, decision_var_dict, model_results, constraint_params)\n",
      "\n",
      "# Plot waterfall profits\n",
      "plot_waterfall_chart( parameters, daily_profits )\n"
     ]
    }
   ],
   "source": [
    "code_type = 'py_file' #options: demo, py_file, notebook\n",
    "\n",
    "# -----------------  ----------------- ----------------- -----------------\n",
    "\n",
    "\n",
    "if code_type == 'demo':\n",
    "    # Get the source code of our coffee example\n",
    "    code_url = \"https://raw.githubusercontent.com/microsoft/OptiGuide/main/benchmark/application/coffee.py\"\n",
    "    response  = requests.get(code_url)\n",
    "\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Get the text content from the response\n",
    "        code = response.text\n",
    "    else:\n",
    "        raise RuntimeError(\"Failed to retrieve the file.\")\n",
    "elif code_type == 'py_file':\n",
    "    code = open('web_scrape_price_data.py', 'r').read()\n",
    "    code += '\\n'\n",
    "    code += open('run_model.py', 'r').read()\n",
    "    code += '\\n'\n",
    "    code += open( 'two_stage.py', \"r\").read()\n",
    "elif code_type == 'notebook':\n",
    "    # Extract code from jupyter notebook\n",
    "    import nbformat\n",
    "    def extract_code_from_notebook(notebook_path):\n",
    "        try:\n",
    "            with open(notebook_path, 'r', encoding='utf-8') as notebook_file:\n",
    "                notebook_content = nbformat.read(notebook_file, as_version=4)\n",
    "\n",
    "            code_cells = []\n",
    "            for cell in notebook_content['cells']:\n",
    "                if cell['cell_type'] == 'code':\n",
    "                    code_cells.append(cell['source'])\n",
    "\n",
    "            code_as_string = '\\n'.join(code_cells)\n",
    "            return code_as_string\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Notebook file '{notebook_path}' not found.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading notebook: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Example usage\n",
    "    notebook_path = 'Battery_Optimization_Shen_Lapp_Poser.ipynb'\n",
    "    code = extract_code_from_notebook(notebook_path)\n",
    "\n",
    "\n",
    "# show the first head and tail of the source code\n",
    "print(\"\\n\".join(code.split(\"\\n\")))\n",
    "print(\".\\n\" * 3)\n",
    "print(\"\\n\".join(code.split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c2f9361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloading price data...\n",
      "----------------------------------------------------------------------\n",
      "...Price data already downloaded for date: 20231004, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231005, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231006, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231007, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231008, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231009, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231010, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231011, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231012, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231013, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231014, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231015, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231016, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231017, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231018, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231019, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231020, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231021, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231022, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231023, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231024, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231025, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231026, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231027, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231028, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231029, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231030, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231031, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231101, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231102, Generator: ADK HUDSON___FALLS\n",
      "...Price data already downloaded for date: 20231103, Generator: ADK HUDSON___FALLS\n",
      "\n",
      " -- Price data downloaded successfully! -- \n",
      "\n",
      "\n",
      "Restricted license - for non-production use only - expires 2024-10-28\n",
      "Gurobi Optimizer version 10.0.0 build v10.0.0rc2 (mac64[arm])\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Model too large for size-limited license; visit https://www.gurobi.com/free-trial for a full license",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exec(code)\n",
      "File \u001b[0;32m<string>:545\u001b[0m\n",
      "File \u001b[0;32m<string>:524\u001b[0m, in \u001b[0;36mstage_one\u001b[0;34m(start_date, parameters)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Code/run_model.py:148\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(parameters, print_results)\u001b[0m\n\u001b[1;32m    145\u001b[0m [model, decision_var_dict, constraint_params] \u001b[38;5;241m=\u001b[39m create_model(parameters)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Run model\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m model\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m GRB\u001b[38;5;241m.\u001b[39mOPTIMAL:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Unpack results\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     model_results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32msrc/gurobipy/model.pxi:875\u001b[0m, in \u001b[0;36mgurobipy.Model.optimize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGurobiError\u001b[0m: Model too large for size-limited license; visit https://www.gurobi.com/free-trial for a full license"
     ]
    }
   ],
   "source": [
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a70331b",
   "metadata": {
    "code_folding": [],
    "id": "e31c4b36"
   },
   "outputs": [],
   "source": [
    "# In-context learning examples.\n",
    "example_qa = \"\"\"\n",
    "\"What if all warehouse costs are 15% more expensive?\"\"\n",
    "----------\n",
    "Question: \n",
    "Answer Code:\n",
    "```python\n",
    "for w in len(parameters['warehouses']):\n",
    "    parameters['warehouse_data'][w]['cost'] *= 1.15\n",
    "```\n",
    "----------\n",
    "\n",
    "Question: \"What if every 14 periods, we can't sell electricity to the grid?\"\n",
    "Answer Code:\n",
    "```python\n",
    "for p in range(num_periods):\n",
    "    if p%14 == 0:\n",
    "        model.addConstr(sell[p] = 0, f'DischargeConstraint_period_{p+1}')\n",
    "```\n",
    "\n",
    "Question: \"What if we have shared warehouse space, and space for batteries decreases by 2.5% each period?\"\n",
    "Answer Code:\n",
    "```python\n",
    "dec = 2.5 * 1/100\n",
    "for p in range(num_periods):\n",
    "    for w in len(parameters['warehouses']):\n",
    "        parameters['warehouse_data'][w]['area'] *= (1 - dec)\n",
    "```\n",
    "\n",
    "Question: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db5598d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18422"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.find( '# OPTIGUIDE DATA CODE GOES HERE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364c898",
   "metadata": {
    "id": "5a5a7d7e"
   },
   "source": [
    "Now, let's create an OptiGuide agent and also a user.\n",
    "\n",
    "For the OptiGuide agent, we only allow \"debug_times\" to be 1, which means it can debug its answer once if it encountered errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4346027a",
   "metadata": {
    "id": "af53727c"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "agent = OptiGuideAgent(\n",
    "    name=\"OptiGuide Super sexy team Example\",\n",
    "    source_code=code,\n",
    "    debug_times=1,\n",
    "    example_qa=example_qa,\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "user = UserProxyAgent(\"user\", max_consecutive_auto_reply=0, human_input_mode=\"NEVER\", code_execution_config=False)\n",
    "\n",
    "# Get open ai key from txt file\n",
    "#api_path = '../credentials/openai_api_key.txt'\n",
    "\n",
    "#with open(api_path, \"r\") as file:\n",
    "#        api_key = file.read().strip()\n",
    "\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d3c84",
   "metadata": {
    "id": "bd615e87"
   },
   "source": [
    "Now, let's create a user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95f7aef0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24a76f67",
    "outputId": "2399e32e-fe3f-429f-9c40-fcc75605741d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "What if all warehouse costs were 13% more expensive\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "Answer Code:\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[flaml.autogen.oai.completion: 12-05 20:57:16] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 7849, Requested 7312. Please try again in 30.966s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:57:26] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 6133, Requested 7312. Please try again in 20.67s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:57:36] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 4446, Requested 7312. Please try again in 10.548s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:57:46] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 2758, Requested 7312. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "\u001b[33mwriter\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "```python\n",
      "# increase each warehouse cost by 13%\n",
      "for w in range(len(parameters['warehouse_data'])):\n",
      "    parameters['warehouse_data'][w]['cost'] *= 1.13\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to safeguard):\n",
      "\n",
      "\n",
      "--- Code ---\n",
      "# increase each warehouse cost by 13%\n",
      "for w in range(len(parameters['warehouse_data'])):\n",
      "    parameters['warehouse_data'][w]['cost'] *= 1.13\n",
      "\n",
      "--- One-Word Answer: SAFE or DANGER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[flaml.autogen.oai.completion: 12-05 20:57:59] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 7532, Requested 7001. Please try again in 27.198s. Visit https://platform.openai.com/account/rate-limits to learn more.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 12-05 20:58:09] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 5841, Requested 7001. Please try again in 17.052s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:58:20] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 4151, Requested 7001. Please try again in 6.912s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "\u001b[33msafeguard\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "SAFE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33minvalid syntax (<string>, line 495)\u001b[0m\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "\n",
      "While running the code you suggested, I encountered the <class 'SyntaxError'>:\n",
      "--- ERROR MESSAGE ---\n",
      "invalid syntax (<string>, line 495)\n",
      "\n",
      "Please try to resolve this bug, and rewrite the code snippet.\n",
      "--- NEW CODE ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[flaml.autogen.oai.completion: 12-05 20:58:30] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 8902, Requested 7408. Please try again in 37.86s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:58:41] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 7214, Requested 7408. Please try again in 27.732s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:58:51] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 5506, Requested 7408. Please try again in 17.484s. Visit https://platform.openai.com/account/rate-limits to learn more.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 12-05 20:59:01] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 3817, Requested 7408. Please try again in 7.35s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "\u001b[33mwriter\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "I apologize for the confusion. There's no issue with the Python code provided. It seems like it might be an issue with integrating the provided code into the existing codebase.\n",
      "\n",
      "Here is the corrected Python code:\n",
      "\n",
      "```python\n",
      "for warehouse in parameters['warehouse_data']:\n",
      "    warehouse['cost'] *= 1.13\n",
      "```\n",
      "\n",
      "The code iterates through each warehouse in the 'warehouse_data' list of dictionaries present in the 'parameters' dictionary, and increases its 'cost' by 13%.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to safeguard):\n",
      "\n",
      "\n",
      "--- Code ---\n",
      "for warehouse in parameters['warehouse_data']:\n",
      "    warehouse['cost'] *= 1.13\n",
      "\n",
      "--- One-Word Answer: SAFE or DANGER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[flaml.autogen.oai.completion: 12-05 20:59:17] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 8250, Requested 6985. Please try again in 31.409s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:59:27] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 6561, Requested 6985. Please try again in 21.276s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:59:37] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 4873, Requested 6985. Please try again in 11.148s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "[flaml.autogen.oai.completion: 12-05 20:59:47] {236} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/Users/ryanshen/Desktop/opt/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-WqyU2py6AtexGlH746WwiXDb on tokens_usage_based per min: Limit 10000, Used 3184, Requested 6985. Please try again in 1.013s. Visit https://platform.openai.com/account/rate-limits to learn more.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33msafeguard\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "SAFE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33minvalid syntax (<string>, line 495)\u001b[0m\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to user):\n",
      "\n",
      "Sorry. I cannot answer your question.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(agent, message=\"What if all warehouse costs were 13% more expensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb71ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668b480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de4ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
