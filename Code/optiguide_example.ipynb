{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd37cf4",
   "metadata": {
    "id": "a461c72d"
   },
   "source": [
    "# OptiGuide Example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc333c12",
   "metadata": {
    "id": "59a05fc7"
   },
   "source": [
    "Here we give a simple example, as designed and illustrated in the [OptiGuide paper](https://arxiv.org/abs/2307.03875).\n",
    "While the original paper is designed specifically for supply chain optimization, the general framework can be easily adapted to other applications with coding capacity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df57b42",
   "metadata": {
    "id": "5e92d200"
   },
   "source": [
    "## OptiGuide for Supply Chain Optimization: System Design Overview\n",
    "\n",
    "The original system design for OptiGuide, tailored for supply chain optimization, is presented below.\n",
    "\n",
    "The collaboration among three agents -- Coder, Safeguard, and Interpreter -- lies at the core of this system. They leverage a set of external tools and a large language model (LLM) to address users' questions related to supply chain applications. For a comprehensive understanding of the design and data flow, detailed information can be found in the original [paper](https://arxiv.org/abs/2307.03875).\n",
    "\n",
    "\n",
    "![optiguide system](https://www.beibinli.com/docs/optiguide/optiguide_system.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec618de",
   "metadata": {
    "id": "8b7f90c8"
   },
   "source": [
    "## New Implementation\n",
    "\n",
    "\n",
    "\n",
    "![](new_design.png)\n",
    "\n",
    "Advantages of this multi-agent design with autogen:\n",
    "- Collaborative Problem Solving: The collaboration among the user proxy agent and the assistant agents fosters a cooperative problem-solving environment. The agents can share information and knowledge, allowing them to complement each other's abilities and collectively arrive at better solutions. On the other hand, the Safeguard acts as a virtual adversarial checker, which can perform another safety check pass on the generated code.\n",
    "\n",
    "- Modularity: The division of tasks into separate agents promotes modularity in the system. Each agent can be developed, tested, and maintained independently, simplifying the overall development process and facilitating code management.\n",
    "\n",
    "- Memory Management: The OptiGuide agent's role in maintaining memory related to user interactions is crucial. The memory retention allows the agents to have context about a user's prior questions, making the decision-making process more informed and context-aware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "444fe547",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReAgLnDma3oI",
    "outputId": "c95a23e8-ddb9-4fd2-f218-c40a51cbcbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optiguide in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (0.0.1)\n",
      "Requirement already satisfied: openai in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from optiguide) (1.3.5)\n",
      "Requirement already satisfied: diskcache in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from optiguide) (5.6.3)\n",
      "Requirement already satisfied: termcolor in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from optiguide) (2.3.0)\n",
      "Requirement already satisfied: flaml in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from optiguide) (2.1.1)\n",
      "Requirement already satisfied: autogen in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from optiguide) (1.0.16)\n",
      "Requirement already satisfied: eventlet in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from optiguide) (0.33.3)\n",
      "Requirement already satisfied: gurobipy in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from optiguide) (10.0.3)\n",
      "Requirement already satisfied: PyYAML in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from autogen->optiguide) (6.0)\n",
      "Requirement already satisfied: autopep8 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from autogen->optiguide) (1.6.0)\n",
      "Requirement already satisfied: docopt in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from autogen->optiguide) (0.6.2)\n",
      "Requirement already satisfied: setuptools in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from autogen->optiguide) (68.0.0)\n",
      "Requirement already satisfied: twine in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from autogen->optiguide) (4.0.2)\n",
      "Requirement already satisfied: dnspython>=1.15.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from eventlet->optiguide) (2.4.2)\n",
      "Requirement already satisfied: greenlet>=0.3 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from eventlet->optiguide) (2.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from eventlet->optiguide) (1.16.0)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from flaml->optiguide) (1.24.3)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai->optiguide) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai->optiguide) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai->optiguide) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai->optiguide) (1.10.8)\n",
      "Requirement already satisfied: tqdm>4 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai->optiguide) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai->optiguide) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai->optiguide) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai->optiguide) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->optiguide) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->optiguide) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->optiguide) (0.14.0)\n",
      "Requirement already satisfied: pycodestyle>=2.8.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from autopep8->autogen->optiguide) (2.10.0)\n",
      "Requirement already satisfied: toml in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from autopep8->autogen->optiguide) (0.10.2)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (1.9.6)\n",
      "Requirement already satisfied: readme-renderer>=35.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (42.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (1.26.16)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (6.0.0)\n",
      "Requirement already satisfied: keyring>=15.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (23.13.1)\n",
      "Requirement already satisfied: rfc3986>=1.4.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (2.0.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from twine->autogen->optiguide) (13.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from importlib-metadata>=3.6->twine->autogen->optiguide) (3.11.0)\n",
      "Requirement already satisfied: jaraco.classes in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from keyring>=15.1->twine->autogen->optiguide) (3.2.1)\n",
      "Requirement already satisfied: nh3>=0.2.14 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (0.2.14)\n",
      "Requirement already satisfied: docutils>=0.13.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (0.18.1)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from requests>=2.20->twine->autogen->optiguide) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from rich>=12.0.0->twine->autogen->optiguide) (2.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->autogen->optiguide) (0.1.0)\n",
      "Requirement already satisfied: more-itertools in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from jaraco.classes->keyring>=15.1->twine->autogen->optiguide) (8.12.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flaml[openai] in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from flaml[openai]) (1.24.3)\n",
      "Collecting openai==0.27.8 (from flaml[openai])\n",
      "  Obtaining dependency information for openai==0.27.8 from https://files.pythonhosted.org/packages/67/78/7588a047e458cb8075a4089d721d7af5e143ff85a2388d4a28c530be0494/openai-0.27.8-py3-none-any.whl.metadata\n",
      "  Using cached openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: diskcache in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from flaml[openai]) (5.6.3)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai==0.27.8->flaml[openai]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai==0.27.8->flaml[openai]) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai==0.27.8->flaml[openai]) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8->flaml[openai]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8->flaml[openai]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8->flaml[openai]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8->flaml[openai]) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->flaml[openai]) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->flaml[openai]) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->flaml[openai]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->flaml[openai]) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->flaml[openai]) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8->flaml[openai]) (1.2.0)\n",
      "Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.3.5\n",
      "    Uninstalling openai-1.3.5:\n",
      "      Successfully uninstalled openai-1.3.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyautogen 0.2.0 requires openai~=1.2, but you have openai 0.27.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-0.27.8\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyautogen in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: diskcache in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: flaml in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from pyautogen) (2.1.1)\n",
      "Collecting openai~=1.2 (from pyautogen)\n",
      "  Obtaining dependency information for openai~=1.2 from https://files.pythonhosted.org/packages/30/1d/27c3571504fb6fb1e9f7c906d93590ead22f5f34910489e155ee28512eeb/openai-1.3.5-py3-none-any.whl.metadata\n",
      "  Using cached openai-1.3.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dotenv in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from pyautogen) (0.21.0)\n",
      "Requirement already satisfied: termcolor in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from pyautogen) (2.3.0)\n",
      "Requirement already satisfied: tiktoken in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from pyautogen) (0.5.1)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai~=1.2->pyautogen) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai~=1.2->pyautogen) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai~=1.2->pyautogen) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai~=1.2->pyautogen) (1.10.8)\n",
      "Requirement already satisfied: tqdm>4 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai~=1.2->pyautogen) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from openai~=1.2->pyautogen) (4.7.1)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from flaml->pyautogen) (1.24.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from tiktoken->pyautogen) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from tiktoken->pyautogen) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai~=1.2->pyautogen) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai~=1.2->pyautogen) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai~=1.2->pyautogen) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai~=1.2->pyautogen) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.2->pyautogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->pyautogen) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/coltonlapp/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->pyautogen) (1.26.16)\n",
      "Using cached openai-1.3.5-py3-none-any.whl (220 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.8\n",
      "    Uninstalling openai-0.27.8:\n",
      "      Successfully uninstalled openai-0.27.8\n",
      "Successfully installed openai-1.3.5\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Required Packages\n",
    "%pip install optiguide\n",
    "%pip install flaml[openai]\n",
    "%pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43cc7263",
   "metadata": {
    "id": "9a3b79c4"
   },
   "outputs": [],
   "source": [
    "# test Gurobi installation\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from eventlet.timeout import Timeout\n",
    "\n",
    "# import auxillary packages\n",
    "import requests  # for loading the example source code\n",
    "import openai\n",
    "\n",
    "# import flaml and autogen\n",
    "from flaml import autogen\n",
    "from flaml.autogen.agentchat import Agent, UserProxyAgent\n",
    "from optiguide.optiguide import OptiGuideAgent\n",
    "\n",
    "from flaml.autogen.agentchat import AssistantAgent\n",
    "from flaml.autogen.agentchat.agent import Agent\n",
    "from flaml.autogen.code_utils import extract_code\n",
    "\n",
    "# %pip install flaml[openai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c1e211",
   "metadata": {
    "id": "aedf19e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autogen.oai.ChatCompletion.start_logging()\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            #\"gpt-4\",\n",
    "            #\"gpt4\",\n",
    "            #\"gpt-4-32k\",\n",
    "            #\"gpt-4-32k-0314\",\n",
    "            #\"gpt-3.5-turbo\"\n",
    "            \"gpt-3.5-turbo-16k\"\n",
    "            #\"gpt-3.5-turbo-0301\",\n",
    "            #\"chatgpt-35-turbo-0301\",\n",
    "            #\"gpt-35-turbo-v0301\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "config_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944272d",
   "metadata": {
    "id": "e9e7e728"
   },
   "source": [
    "Now, let's import the source code (loading from URL) and also some training examples (defined as string blow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05664eac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca962ac5",
    "outputId": "4a789991-8ba1-46f3-aad5-7fbaaaff7f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import time\n",
      "from gurobipy import GRB, Model\n",
      "\n",
      "# Example data\n",
      "\n",
      "capacity_in_supplier = {'supplier1': 150, 'supplier2': 50, 'supplier3': 100}\n",
      "\n",
      "shipping_cost_from_supplier_to_roastery = {\n",
      "    ('supplier1', 'roastery1'): 5,\n",
      "    ('supplier1', 'roastery2'): 4,\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "# Solve\n",
      "m.update()\n",
      "model.optimize()\n",
      "\n",
      "print(time.ctime())\n",
      "if m.status == GRB.OPTIMAL:\n",
      "    print(f'Optimal cost: {m.objVal}')\n",
      "else:\n",
      "    print(\"Not solved to optimality. Optimization status:\", m.status)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import time\\nfrom gurobipy import GRB, Model\\n\\n# Example data\\n\\ncapacity_in_supplier = {\\'supplier1\\': 150, \\'supplier2\\': 50, \\'supplier3\\': 100}\\n\\nshipping_cost_from_supplier_to_roastery = {\\n    (\\'supplier1\\', \\'roastery1\\'): 5,\\n    (\\'supplier1\\', \\'roastery2\\'): 4,\\n    (\\'supplier2\\', \\'roastery1\\'): 6,\\n    (\\'supplier2\\', \\'roastery2\\'): 3,\\n    (\\'supplier3\\', \\'roastery1\\'): 2,\\n    (\\'supplier3\\', \\'roastery2\\'): 7\\n}\\n\\nroasting_cost_light = {\\'roastery1\\': 3, \\'roastery2\\': 5}\\n\\nroasting_cost_dark = {\\'roastery1\\': 5, \\'roastery2\\': 6}\\n\\nshipping_cost_from_roastery_to_cafe = {\\n    (\\'roastery1\\', \\'cafe1\\'): 5,\\n    (\\'roastery1\\', \\'cafe2\\'): 3,\\n    (\\'roastery1\\', \\'cafe3\\'): 6,\\n    (\\'roastery2\\', \\'cafe1\\'): 4,\\n    (\\'roastery2\\', \\'cafe2\\'): 5,\\n    (\\'roastery2\\', \\'cafe3\\'): 2\\n}\\n\\nlight_coffee_needed_for_cafe = {\\'cafe1\\': 20, \\'cafe2\\': 30, \\'cafe3\\': 40}\\n\\ndark_coffee_needed_for_cafe = {\\'cafe1\\': 20, \\'cafe2\\': 20, \\'cafe3\\': 100}\\n\\ncafes = list(set(i[1] for i in shipping_cost_from_roastery_to_cafe.keys()))\\nroasteries = list(\\n    set(i[1] for i in shipping_cost_from_supplier_to_roastery.keys()))\\nsuppliers = list(\\n    set(i[0] for i in shipping_cost_from_supplier_to_roastery.keys()))\\n\\n# Create a new model\\nmodel = Model(\"coffee_distribution\")\\n\\n# OPTIGUIDE DATA CODE GOES HERE\\n\\n# Create variables\\nx = model.addVars(shipping_cost_from_supplier_to_roastery.keys(),\\n                  vtype=GRB.INTEGER,\\n                  name=\"x\")\\ny_light = model.addVars(shipping_cost_from_roastery_to_cafe.keys(),\\n                        vtype=GRB.INTEGER,\\n                        name=\"y_light\")\\ny_dark = model.addVars(shipping_cost_from_roastery_to_cafe.keys(),\\n                       vtype=GRB.INTEGER,\\n                       name=\"y_dark\")\\n\\n# Set objective\\nmodel.setObjective(\\n    sum(x[i] * shipping_cost_from_supplier_to_roastery[i]\\n        for i in shipping_cost_from_supplier_to_roastery.keys()) +\\n    sum(roasting_cost_light[r] * y_light[r, c] +\\n        roasting_cost_dark[r] * y_dark[r, c]\\n        for r, c in shipping_cost_from_roastery_to_cafe.keys()) + sum(\\n            (y_light[j] + y_dark[j]) * shipping_cost_from_roastery_to_cafe[j]\\n            for j in shipping_cost_from_roastery_to_cafe.keys()), GRB.MINIMIZE)\\n\\n# Conservation of flow constraint\\nfor r in set(i[1] for i in shipping_cost_from_supplier_to_roastery.keys()):\\n    model.addConstr(\\n        sum(x[i] for i in shipping_cost_from_supplier_to_roastery.keys()\\n            if i[1] == r) == sum(\\n                y_light[j] + y_dark[j]\\n                for j in shipping_cost_from_roastery_to_cafe.keys()\\n                if j[0] == r), f\"flow_{r}\")\\n\\n# Add supply constraints\\nfor s in set(i[0] for i in shipping_cost_from_supplier_to_roastery.keys()):\\n    model.addConstr(\\n        sum(x[i] for i in shipping_cost_from_supplier_to_roastery.keys()\\n            if i[0] == s) <= capacity_in_supplier[s], f\"supply_{s}\")\\n\\n# Add demand constraints\\nfor c in set(i[1] for i in shipping_cost_from_roastery_to_cafe.keys()):\\n    model.addConstr(\\n        sum(y_light[j] for j in shipping_cost_from_roastery_to_cafe.keys()\\n            if j[1] == c) >= light_coffee_needed_for_cafe[c],\\n        f\"light_demand_{c}\")\\n    model.addConstr(\\n        sum(y_dark[j] for j in shipping_cost_from_roastery_to_cafe.keys()\\n            if j[1] == c) >= dark_coffee_needed_for_cafe[c],\\n        f\"dark_demand_{c}\")\\n\\n# Optimize model\\nmodel.optimize()\\nm = model\\n\\n# OPTIGUIDE CONSTRAINT CODE GOES HERE\\n\\n# Solve\\nm.update()\\nmodel.optimize()\\n\\nprint(time.ctime())\\nif m.status == GRB.OPTIMAL:\\n    print(f\\'Optimal cost: {m.objVal}\\')\\nelse:\\n    print(\"Not solved to optimality. Optimization status:\", m.status)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the source code of our coffee example\n",
    "code_url = \"https://raw.githubusercontent.com/microsoft/OptiGuide/main/benchmark/application/coffee.py\"\n",
    "response  = requests.get(code_url)\n",
    "\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the text content from the response\n",
    "    code = response.text\n",
    "else:\n",
    "    raise RuntimeError(\"Failed to retrieve the file.\")\n",
    "\n",
    "\n",
    "#code = open( 'Battery_Optimization_Shen_Lapp_Poser.ipynb', \"r\").read() # for local files\n",
    "\n",
    "\n",
    "# show the first head and tail of the source code\n",
    "print(\"\\n\".join(code.split(\"\\n\")[:10]))\n",
    "print(\".\\n\" * 3)\n",
    "print(\"\\n\".join(code.split(\"\\n\")[-10:]))\n",
    "\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install webdriver_manager\\nimport os\\nimport re\\nimport time\\nimport numpy as np\\nimport pandas as pd\\nimport gurobipy as gp\\nimport sys\\nfrom gurobipy import GRB\\nfrom datetime import datetime\\nfrom selenium import webdriver\\nfrom webdriver_manager.chrome import ChromeDriverManager\\nparameters = {\\n    \\'name\\': \\'ElectricityArbitrage\\',\\n    \\'generator_name\\': \\'ADK HUDSON___FALLS\\',\\n    \\'start_date\\': None,\\n    \\'num_periods\\': 24,\\n    \\'num_markets\\': 1,\\n    \\'num_batteries\\': 8,\\n    \\'battery_capacity\\': 100,\\n    \\'charge_loss\\': 0.95,\\n    \\'max_charge\\': 50,\\n    \\'max_discharge\\': 100\\n}\\n\\n# OPTIGUIDE DATA CODE GOES HERE\\ndef extract_date(file_path):\\n    match = re.match(r\\'^(\\\\d+)\\', file_path.split(\\'/\\')[4])\\n\\n    return match.group(1)\\ndef get_prices(start_date, generator_name):\\n    if start_date == None:\\n        start_date = datetime.today()\\n        start_date = start_date.strftime(\"%Y%m%d\")\\n\\n    dates = [start_date]\\n\\n    driver_path = ChromeDriverManager().install()\\n\\n    home_dir = os.path.expanduser(\"~\")\\n\\n    download_directory = os.path.join(home_dir, \\'Downloads_CSV\\')\\n    chrome_options = webdriver.ChromeOptions()\\n    prefs = {\\'download.default_directory\\': download_directory}\\n    chrome_options.add_experimental_option(\\'prefs\\', prefs)\\n\\n    # Initialize the driver, use try except blocks depending on version of selenium installed\\n    try:\\n        # Older selenium version that takes executable path as argument\\n        driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\\n    except:\\n        try:\\n            # For selenium version 3.141.0 or above\\n            driver=webdriver.Chrome(options=chrome_options)\\n        except:\\n            sys.exit(\"Please install correct version of selenium\")\\n\\n    driver.get(\\'http://mis.nyiso.com/public/P-24Blist.htm\\')\\n    all_links = driver.find_elements(\"xpath\", \"//a[@href]\")\\n\\n    if not os.path.exists(download_directory):\\n        os.makedirs(download_directory)\\n\\n    for date in dates:\\n        for link in all_links:\\n            href = link.get_attribute(\\'href\\')\\n\\n            if (\\'csv\\' in href) and (date in href):\\n                link.click()\\n                time.sleep(2)\\n                break\\n\\n    csv_files = [file for file in os.listdir(download_directory) if file.endswith(\\'.csv\\')]\\n    prices_by_date = {}\\n\\n    for file_name in csv_files:\\n        file_path = os.path.join(download_directory, file_name)\\n        date = extract_date(file_path)\\n        df = pd.read_csv(file_path)\\n        prices = df[df[\\'Name\\'] == generator_name][[\\'LBMP ($/MWHr)\\']].values.tolist()\\n\\n        prices_by_date[date] = prices\\n\\n    driver.quit()\\n\\n    return prices_by_date\\ndef create_model(parameters): # num_markets is going to be 1 for the time being\\n    name = parameters[\\'name\\']\\n    generator_name = parameters[\\'generator_name\\']\\n    start_date = parameters[\\'start_date\\']\\n    num_periods = parameters[\\'num_periods\\']\\n    num_markets = parameters[\\'num_markets\\']\\n    num_batteries = parameters[\\'num_batteries\\']\\n    battery_capacity = parameters[\\'battery_capacity\\']\\n    charge_loss = parameters[\\'charge_loss\\']\\n    max_charge = parameters[\\'max_charge\\']\\n    max_discharge = parameters[\\'max_discharge\\']\\n\\n    model = gp.Model(name)\\n\\n    periods = range(num_periods)\\n    markets = range(num_markets)\\n\\n    buy = model.addVars(num_periods, num_markets, vtype=GRB.CONTINUOUS, name=\\'Buy\\')\\n    sell = model.addVars(num_periods, num_markets, vtype=GRB.CONTINUOUS, name=\\'Sell\\')\\n\\n    prices_by_date = get_prices(start_date, generator_name)\\n\\n    # placeholder\\n    start_date = datetime.today()\\n    start_date = start_date.strftime(\"%Y%m%d\")\\n\\n    print(prices_by_date)\\n    print(start_date)\\n\\n    prices = prices_by_date[start_date]\\n\\n    model.setObjective(\\n        gp.quicksum(prices[p][i] * sell[p, i] - prices[p][i] * buy[p, i] for p in periods for i in markets),\\n        GRB.MAXIMIZE\\n    )\\n\\n    for p in range(num_periods):\\n        current_level = np.sum(charge_loss * buy[p_, i] - sell[p_, i] for p_ in range(p) for i in markets)\\n\\n        # model.addConstr(current_level <= 0, f\\'EnoughToSellConstraint_period_{p+1}\\')\\n\\n        for i in markets:\\n            model.addConstr(current_level <= battery_capacity * num_batteries, f\\'CapacityConstraint_period_{p+1}\\')\\n            model.addConstr(sell[p, i] <= current_level, f\\'SupplyConstraint_period_{p+1}\\')\\n            model.addConstr(buy[p, i] * charge_loss <= max_charge, f\\'ChargeConstraint_period_{p+1}\\')\\n            model.addConstr(sell[p, i] <= max_discharge, f\\'DischargeConstraint_period_{p+1}\\')\\n\\n    # OPTIGUIDE CONSTRAINT CODE GOES HERE\\n\\n    return [model, buy, sell]\\ndef print_model(model, buy, sell, parameters):\\n    num_periods = parameters[\\'num_periods\\']\\n    num_markets = parameters[\\'num_markets\\']\\n\\n    if model.status == GRB.OPTIMAL:\\n        print(\"\\\\nOptimal Solution:\")\\n\\n        for p in range(num_periods):\\n            print(f\"\\\\nPeriod {p + 1}:\")\\n\\n            for i in range(num_markets):\\n                print(f\"Buy from Market {i + 1}: {buy[p, i].x}\")\\n                print(f\"Sell to Market {i + 1}: {sell[p, i].x}\")\\n\\n        print(f\"\\\\nTotal Profit: {model.objVal}\")\\n    else:\\n        print(\"No solution found\")\\ndef run(parameters):\\n    [model, buy, sell] = create_model(parameters)\\n\\n    model.optimize()\\n\\n    return [model, buy, sell]\\n\\n    print_model(model, buy, sell, parameters)\\nrun(parameters)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract code from jupyter notebook\n",
    "\n",
    "import nbformat\n",
    "\n",
    "def extract_code_from_notebook(notebook_path):\n",
    "    try:\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as notebook_file:\n",
    "            notebook_content = nbformat.read(notebook_file, as_version=4)\n",
    "\n",
    "        code_cells = []\n",
    "        for cell in notebook_content['cells']:\n",
    "            if cell['cell_type'] == 'code':\n",
    "                code_cells.append(cell['source'])\n",
    "\n",
    "        code_as_string = '\\n'.join(code_cells)\n",
    "        return code_as_string\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Notebook file '{notebook_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading notebook: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "notebook_path = 'Battery_Optimization_Shen_Lapp_Poser.ipynb'\n",
    "our_code = extract_code_from_notebook(notebook_path)\n",
    "\n",
    "our_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a70331b",
   "metadata": {
    "code_folding": [],
    "id": "e31c4b36"
   },
   "outputs": [],
   "source": [
    "# In-context learning examples.\n",
    "example_qa = \"\"\"\n",
    "----------\n",
    "Question: What if the battery charge capacity was only 70 percent instead of 95 percent?\n",
    "Answer Code:\n",
    "```python\n",
    "parameters['charge_loss'] = .7\n",
    "```\n",
    "----------\n",
    "Question: What if we had 20 batteries instead of 8?\n",
    "Answer Code:\n",
    "```python\n",
    " parameters['num_batteries'] = 8\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_code.find( '# OPTIGUIDE DATA GOES HERE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364c898",
   "metadata": {
    "id": "5a5a7d7e"
   },
   "source": [
    "Now, let's create an OptiGuide agent and also a user.\n",
    "\n",
    "For the OptiGuide agent, we only allow \"debug_times\" to be 1, which means it can debug its answer once if it encountered errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4346027a",
   "metadata": {
    "id": "af53727c"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "agent = OptiGuideAgent(\n",
    "    name=\"OptiGuide Super sexy team Example\",\n",
    "    source_code=our_code,\n",
    "    debug_times=1,\n",
    "    example_qa=\"\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "user = UserProxyAgent(\n",
    "    \"user\", max_consecutive_auto_reply=0,\n",
    "    human_input_mode=\"NEVER\", code_execution_config=False\n",
    ")\n",
    "\n",
    "# Get open ai key from txt file\n",
    "api_path = '../credentials/openai_api_key.txt'\n",
    "\n",
    "def read_api_key(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            api_key = file.read().strip()\n",
    "        return api_key\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    \n",
    "openai.api_key = read_api_key(api_path)\n",
    "openai.api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d3c84",
   "metadata": {
    "id": "bd615e87"
   },
   "source": [
    "Now, let's create a user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f7aef0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24a76f67",
    "outputId": "2399e32e-fe3f-429f-9c40-fcc75605741d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "What would the profit be if we increased the max charge to 70?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "Answer Code:\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "```python\n",
      "parameters['max_charge'] = 70\n",
      "[model, buy, sell] = run(parameters)\n",
      "print_model(model, buy, sell, parameters)\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to safeguard):\n",
      "\n",
      "\n",
      "--- Code ---\n",
      "parameters['max_charge'] = 70\n",
      "[model, buy, sell] = run(parameters)\n",
      "print_model(model, buy, sell, parameters)\n",
      "\n",
      "--- One-Word Answer: SAFE or DANGER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msafeguard\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "SAFE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33minvalid syntax (<string>, line 1)\u001b[0m\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "\n",
      "While running the code you suggested, I encountered the <class 'SyntaxError'>:\n",
      "--- ERROR MESSAGE ---\n",
      "invalid syntax (<string>, line 1)\n",
      "\n",
      "Please try to resolve this bug, and rewrite the code snippet.\n",
      "--- NEW CODE ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "Apologies for misunderstanding. The `run` and `print_model` functions from original code needs to be separately called to correctly run the model and then print the results. Here is the correct code snippet:\n",
      "\n",
      "```python\n",
      "parameters['max_charge'] = 70\n",
      "[model, buy, sell] = run(parameters)\n",
      "print_model(model, buy, sell, parameters)\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to safeguard):\n",
      "\n",
      "\n",
      "--- Code ---\n",
      "parameters['max_charge'] = 70\n",
      "[model, buy, sell] = run(parameters)\n",
      "print_model(model, buy, sell, parameters)\n",
      "\n",
      "--- One-Word Answer: SAFE or DANGER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msafeguard\u001b[0m (to OptiGuide Super sexy team Example):\n",
      "\n",
      "SAFE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33minvalid syntax (<string>, line 1)\u001b[0m\n",
      "\u001b[33mOptiGuide Super sexy team Example\u001b[0m (to user):\n",
      "\n",
      "Sorry. I cannot answer your question.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(agent, message='What would the profit be if we increased the max charge to 70?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726edebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbdd1f28",
    "outputId": "c5e943cf-fce7-4484-8cd8-433d4fede8e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to OptiGuide Coffee Example):\n",
      "\n",
      "What is the impact of supplier1 being able to supply only half the quantity at present?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Coffee Example\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "Answer Code:\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to OptiGuide Coffee Example):\n",
      "\n",
      "```python\n",
      "# Adjust the supplier capacity\n",
      "capacity_in_supplier['supplier1'] /= 2\n",
      "\n",
      "# Update supply constraints\n",
      "for s in set(i[0] for i in shipping_cost_from_supplier_to_roastery.keys()):\n",
      "    if s == 'supplier1':\n",
      "        model.remove(model.getConstrByName(f\"supply_{s}\"))\n",
      "        model.addConstr(sum(x[i] for i in shipping_cost_from_supplier_to_roastery.keys() if i[0] == s) <= capacity_in_supplier[s], f\"supply_{s}\")\n",
      "# Rerun the optimization\n",
      "model.optimize()\n",
      "\n",
      "if model.status == GRB.OPTIMAL:\n",
      "    print(f'Optimal cost after supplier1 supply reduction: {model.objVal}')\n",
      "else:\n",
      "    print(\"Not solved to optimality. Optimization status:\", model.status)\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "First, we reduce the capacity of 'supplier1' by half in the 'capacity_in_supplier' dictionary. Then, we update 'supplier1' constraint in the model: we first remove its existing supply constraint, and then add a new one with the updated capacity. After these updates, we run the optimization again. If the solution is optimal, we print out the new optimal cost. If not, we print out the optimization status.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Coffee Example\u001b[0m (to safeguard):\n",
      "\n",
      "\n",
      "--- Code ---\n",
      "# Adjust the supplier capacity\n",
      "capacity_in_supplier['supplier1'] /= 2\n",
      "\n",
      "# Update supply constraints\n",
      "for s in set(i[0] for i in shipping_cost_from_supplier_to_roastery.keys()):\n",
      "    if s == 'supplier1':\n",
      "        model.remove(model.getConstrByName(f\"supply_{s}\"))\n",
      "        model.addConstr(sum(x[i] for i in shipping_cost_from_supplier_to_roastery.keys() if i[0] == s) <= capacity_in_supplier[s], f\"supply_{s}\")\n",
      "# Rerun the optimization\n",
      "model.optimize()\n",
      "\n",
      "if model.status == GRB.OPTIMAL:\n",
      "    print(f'Optimal cost after supplier1 supply reduction: {model.objVal}')\n",
      "else:\n",
      "    print(\"Not solved to optimality. Optimization status:\", model.status)\n",
      "\n",
      "--- One-Word Answer: SAFE or DANGER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msafeguard\u001b[0m (to OptiGuide Coffee Example):\n",
      "\n",
      "SAFE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M1 Pro\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 11 rows, 18 columns and 36 nonzeros\n",
      "Model fingerprint: 0x01a67d7b\n",
      "Variable types: 0 continuous, 18 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e+00, 1e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 2e+02]\n",
      "Found heuristic solution: objective 3280.0000000\n",
      "Presolve time: 0.00s\n",
      "Presolved: 11 rows, 18 columns, 36 nonzeros\n",
      "Variable types: 0 continuous, 18 integer (0 binary)\n",
      "Found heuristic solution: objective 3276.0000000\n",
      "\n",
      "Root relaxation: objective 2.470000e+03, 11 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    2470.0000000 2470.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (11 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 2470 3276 3280 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.470000000000e+03, best bound 2.470000000000e+03, gap 0.0000%\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M1 Pro\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 11 rows, 18 columns and 36 nonzeros\n",
      "Model fingerprint: 0x591c7dc1\n",
      "Variable types: 0 continuous, 18 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e+00, 1e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 1e+02]\n",
      "\n",
      "MIP start from previous solve did not produce a new incumbent solution\n",
      "MIP start from previous solve violates constraint supply_supplier1 by 5.000000000\n",
      "\n",
      "Presolve time: 0.00s\n",
      "Presolved: 11 rows, 18 columns, 36 nonzeros\n",
      "Variable types: 0 continuous, 18 integer (0 binary)\n",
      "\n",
      "Root relaxation: infeasible, 14 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 infeasible    0               - infeasible      -     -    0s\n",
      "\n",
      "Explored 1 nodes (14 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n",
      "Not solved to optimality. Optimization status: 3\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M1 Pro\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 11 rows, 18 columns and 36 nonzeros\n",
      "Model fingerprint: 0x591c7dc1\n",
      "Variable types: 0 continuous, 18 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e+00, 1e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 1e+02]\n",
      "Presolved: 11 rows, 18 columns, 36 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      "\n",
      "Explored 1 nodes (14 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n",
      "Tue Nov 14 13:10:20 2023\n",
      "Not solved to optimality. Optimization status: 3\n",
      "\n",
      "Computing Irreducible Inconsistent Subsystem (IIS)...\n",
      "\n",
      "           Constraints          |            Bounds           |  Runtime\n",
      "      Min       Max     Guess   |   Min       Max     Guess   |\n",
      "--------------------------------------------------------------------------\n",
      "        0        11         -         0        18         -           0s\n",
      "       11        11        11         0         0         0           0s\n",
      "\n",
      "IIS computed: 11 constraints, 0 bounds\n",
      "IIS runtime: 0.01 seconds (0.00 work units)\n",
      "\u001b[33minfeasible\n",
      "Conflicting Constraints:\n",
      "['flow_roastery1', 'flow_roastery2', 'supply_supplier2', 'supply_supplier3', 'light_demand_cafe2', 'dark_demand_cafe2', 'light_demand_cafe3', 'dark_demand_cafe3', 'light_demand_cafe1', 'dark_demand_cafe1', 'supply_supplier1']\u001b[0m\n",
      "\u001b[33mOptiGuide Coffee Example\u001b[0m (to writer):\n",
      "\n",
      "Here are the execution results: infeasible\n",
      "Conflicting Constraints:\n",
      "['flow_roastery1', 'flow_roastery2', 'supply_supplier2', 'supply_supplier3', 'light_demand_cafe2', 'dark_demand_cafe2', 'light_demand_cafe3', 'dark_demand_cafe3', 'light_demand_cafe1', 'dark_demand_cafe1', 'supply_supplier1']\n",
      "\n",
      "Can you organize these information to a human readable answer?\n",
      "Remember to compare the new results to the original results you obtained in the\n",
      "beginning.\n",
      "\n",
      "--- HUMAN READABLE ANSWER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to OptiGuide Coffee Example):\n",
      "\n",
      "After reducing the supply capacity of 'supplier1' by half, the supply chain optimization problem became infeasible. This means that with the current capacities of suppliers, roasteries, and shipper, we were not able to meet all demands from all cafes.\n",
      "\n",
      "The list of conflicting constraints is:\n",
      "* Flows from roasteries 'roastery1' and 'roastery2'\n",
      "* The supply from 'supplier2', 'supplier3', and 'supplier1'\n",
      "* Light and dark coffee demand for 'cafe1', 'cafe2', and 'cafe3'\n",
      "\n",
      "This indicates issues with ensuring supply, distributing supply to roasteries, and meeting coffee demands.\n",
      "\n",
      "To address this, we may need to increase the capacities of other suppliers, increase the throughput of roasteries, or amend the distribution strategy. Alternatively, it may be necessary to negotiate the demands with cafes, in order to match the available supplies.\n",
      "\n",
      "Remember, the original cost before capacity change of 'supplier1' was 2470, which is not achievable under the current situation. The optimization result indicates critical dependency on 'supplier1' and noises the need for diversifying the sources or increasing flexibilities in supply chain design.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOptiGuide Coffee Example\u001b[0m (to user):\n",
      "\n",
      "After reducing the supply capacity of 'supplier1' by half, the supply chain optimization problem became infeasible. This means that with the current capacities of suppliers, roasteries, and shipper, we were not able to meet all demands from all cafes.\n",
      "\n",
      "The list of conflicting constraints is:\n",
      "* Flows from roasteries 'roastery1' and 'roastery2'\n",
      "* The supply from 'supplier2', 'supplier3', and 'supplier1'\n",
      "* Light and dark coffee demand for 'cafe1', 'cafe2', and 'cafe3'\n",
      "\n",
      "This indicates issues with ensuring supply, distributing supply to roasteries, and meeting coffee demands.\n",
      "\n",
      "To address this, we may need to increase the capacities of other suppliers, increase the throughput of roasteries, or amend the distribution strategy. Alternatively, it may be necessary to negotiate the demands with cafes, in order to match the available supplies.\n",
      "\n",
      "Remember, the original cost before capacity change of 'supplier1' was 2470, which is not achievable under the current situation. The optimization result indicates critical dependency on 'supplier1' and noises the need for diversifying the sources or increasing flexibilities in supply chain design.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(agent, message=\"What is the impact of supplier1 being able to supply only half the quantity at present?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb71ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668b480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
